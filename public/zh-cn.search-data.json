{"/about/":{"data":{"":" 待补充测试 测试 待补充测试 测试 待补充测试 测试 "},"title":"关于"},"/documentation/":{"data":{"":"\n人工智能 机器学习，深度学习，强化学习，计算机视觉，自然语言处理，MLOps，生成式人工智能，通用人工智能…..\n大数据 传输，存储，计算，展示；Flink，Kafka, Airflow\\DS，Zeppelin\\StreamPark，StarRocks\\Doris，Iceberg……\n云计算 云原生（容器化）…..\n物联网 边缘计算（边缘AI推理，IoT数据处理，联邦学习）….."},"title":"文档"},"/documentation/ai/":{"data":{"":" 端到端的机器学习简单易用，功能强大丰富。 深度学习简单易用，功能强大丰富。 生成式人工智能大模型 模型部署 MLOps简单易用，功能强大丰富。 分布式训练简单易用，功能强大丰富。 ","创建投资组合#创建投资组合":"选择与众不同的新颖项目创建投资组合：\n以 Kaggle 和 阿里天池 等竞赛网站为起点； 将报告在微信公众号、知乎、掘金等平台展示结果； 在 Github 上托管个人博客； 考虑录制一段简短的视频，展示您的发现； ","参考网址#参考网址：":" 应用机器学习获得报酬 2024 年成为数据科学家的学习路径 2024 年学习生成式人工智能的最佳路线图 从数据收集到模型部署：数据科学项目的 6 个阶段 - KDnuggets 全面的 MLOps 学习路径：2024 年版 MLOps 概述 ","学习路径#学习路径":" flowchart LR classDef someclassA fill:#58C9B9 classDef someclassB fill:#9DC8C8 classDef someclassC fill:#f100,stroke-width:1px classDef someclassD fill:#a3c9c7 classDef someclassE fill:#fff,stroke:#fff,color:#fff classDef someclassF fill:#ff9900 A(人工智能):::someclassA A -- 阶段0：基础 --\u003e B(基础知识):::someclassB --\u003e B1(Python\\ R):::someclassC -.-\u003e B2(线性代数\n微积分):::someclassC -.-\u003e B3(概率论\n数理统计\n贝叶斯统计):::someclassC A -- 阶段1：入门 --\u003e C(端到端的\n机器学习):::someclassA --\u003e C12(机器学习概述) --\u003e C13(机器学习算法) --\u003e C14(建模工具\nSklearn) --\u003e C15(建模步骤\nCRISP-DM) --\u003e Y C -.-\u003e C21(自动机器学习\nAuto ML):::someclassC -.-\u003e C22(大数据集处理):::someclassC A -- 阶段2：进阶 --\u003e D(深度学习):::someclassA --\u003e D11(深度学习概述) --\u003e D12(深度学习算法) --\u003e D13(建模工具\nkeras\nPyTorch\nTensorflow\nFastAI) D -.-\u003e D21(深度解析算法):::someclassC -.-\u003e D22(自制框架\nDeZero):::someclassC -.-\u003e D23(工具源码):::someclassC D13 --\u003e D141(自然语言\nNLP) --\u003e Y D13 --\u003e D142(计算机视觉\nCV) --\u003e Y A -- 阶段3：先进 --\u003e F(生成式\n人工智能):::someclassA --\u003e F1(提示工程) F3(从头构建\n生成模型) --\u003e F4(最新趋势\n\\研究\\论文) --\u003e Y F1 --\u003e F21(NLP -\u003e LLM) --\u003e F3 F1 --\u003e F22(CV -\u003e VLM) --\u003e F3 Y(练习\nUCI 数据集\n竞赛\nkaggle\n阿里天池\n...):::someclassA --\u003e Z A -- 阶段4：部署 --\u003e Z1 Z(模型部署\nMLOps):::someclassF Z1(版本控制\\协作:\nGit\\Github) -.-\u003e Z12(操作系统:Linux\n容器化\\云:Docker) -.-\u003e Z13(ML应用平台：\nHF Spaces\\\nStreamlit Sharing) -.-\u003e Z2(《MLOps 概述》\n部署方式\n核心概念\n......) --\u003e Z3(《主要内容》\n自动化管道\n监控\n生命周期管理\n治理) --\u003e Z4(《管理工具》\nMLFlow\nDVC\nPolyaxon\nMetaflow\nKubeflow) Z4 --\u003e Z A -- 补充知识 --\u003e G1(集成学习):::someclassB -.- G2(时间序列):::someclassB -.- G3(迁移学习):::someclassB -.- G4(强化学习):::someclassB -.- G5(专业知识):::someclassB","补充知识#补充知识":"1、集成学习 主要内容参考如下：\n了解集成学习相关概念； 学习集成学习常用算法及集成学习方法体系（Bagging，Boosting，Stacking，Blending，等）； 学习集成学习 Python 库（Scikit-learn，XGBoost，LightGBM，CatBoost）； 练习\\实践。如，小数据集 UCI ML 或 kaggle 等； 通过 Flask API 或 Streamlit\\Gradio 部署应用； 推荐阅读：\n《集成学习：基础与算法》 - 周志华，李楠 2、领域专业知识 作为数据科学家，需要具备解决相关领域的问题，需要理解相关领域的专业知识。 领域专业知识：\n学习不同领域专业知识，如保险，信贷，物流，电商等； 通过研究竞赛平台多领域数据科学问题，获得 多样化的经验 培养 解决问题的技能； 可以通过收集的行业知识\\信息，分析案例，创建行业知识库； ","阶段-0基础知识#阶段 0：基础知识":" 微积分是研究变化\\微分与累积\\积分的数学分支，用于解决运动、曲线、面积等动态问题。 AI 基础 线性代数是研究向量、矩阵和线性变换的数学分支，核心用来解方程、处理空间变换和数据分析。 AI 基础 概率论是研究随机现象规律性的数学分支，用概率量化不确定性。 AI 基础 数理统计是用数学工具（尤其是概率论）从数据中预测未知的学科，核心是抽样、估计和假设检验。 AI 基础 Python一种广泛使用的解释型、高级和通用的编程语言。 AI 基础 ","阶段-1端到端的机器学习#阶段 1：端到端的机器学习":" 以学习完整的建模过程为主要目标，以了解常用机器算法（优缺点，原理，步骤，应用）和学习建模工具（Sklearn\\ scikit-learn）为次要目标， 快速熟悉端到端的建模过程。 实践多个案例，熟悉端到端的建模过程，主要内容参考如下：\n了解人工智能，机器学习，深度学习，统计机器学习等相关概念； 学习常用算法原理。了解算法优缺点，原理，步骤，应用即可，不必过多关注数学公式； 学习建模分步过程。如：CRISP-DM； 学习建模工具。如：scikit-learn； 在小数据集上练习。如： the UC Irvine Machine Learning Repository； 将模型打包或序列化后的结果部署为 Flask API 或 Streamlit\\Gradio 应用； 补充内容：\n了解自动化机器学习工具。 了解处理大数据集的 python 库。 推荐阅读：\n《深度学习：从基础到实践》 （上册）- [美] Andrew Glassner 《Machine Learning with Python Cookbook》 Chris Albon 《machine-learning-mastery-with-python》 Jason Brownlee 《菜菜的机器学习sklearn课堂》 《机器学习实战：基于Scikit-Learn和TensorFlow》 （法）奥雷利安·杰龙 《Python机器学习》 （美）塞巴斯蒂安·拉施卡（Sebastian Raschka） （美）瓦希德·米尔贾利利（Vahid Mirjalili） NumpyPython 科学计算的基本包；强大的 N 维数组；数值计算工具。 数据分析 Pandas一个快速、强大、灵活且易于使用的开源数据分析和操作工具。 数据分析 SklearnPython 中的机器学习；简单有效的预测数据分析工具。 机器学习 ","阶段-2深度学习#阶段 2：深度学习":"深度学习，主要内容参考如下：\n了解深度学习相关概念； 学习深度学习常用算法及深度学习方法体系（CNN，RNN，LSTM，Transformer，等）； 学习深度学习框架\\工具（keras，PyTorch，Tensorflow，FastAI）； 学习自然语言处理，计算机视觉； 在 KAggle，阿里天池上练习； 补充内容：\n机器学习算法深度解析，需要一定数学基础（线性代数，微积分，概率论与数理统计）。 从头开始理解机器学习算法将帮助您为任务选择正确的算法，解释结果，解决高级问题，将算法扩展到新应用程序，并提高现有算法的性能。 深度解析机器学习算法； 学习深度学习自制框架：DeZero； 学习框架\\工具源码； 推荐阅读：\n《深度学习：从基础到实践》 （下册）- [美] Andrew Glassner 《深度学习入门基于Python的理论与实现》 - [日] 斋藤康毅 《深度学习入门2自制框架》 - [日] 斋藤康毅 《深度学习进阶：自然语言处理》 - [日] 斋藤康毅 《深度学习入门4：强化学习》 - [日] 斋藤康毅 《achine Learning Algorithms in Depth》 - VADIM SMOLYAKOV 《统计学习方法》 (第2版) - 李航 《机器学习》（西瓜书）- 周志华 ","阶段-3生成式人工智能#阶段 3：生成式人工智能":"深入研究高级人工智能主题，关注生成模型：\n学习提示工程（专注于创建和改进提示）。如：coze； NLP 的生成模型，LLM（大语言模型）； 计算机视觉的生成模型； 了解如何从头开始构建这些生成模型； 了解生成人工智能的最新趋势和研究； 推荐阅读：\n2024 年学习生成式人工智能的最佳路线图 机器学习的最新进展带代码的论文 10 个学习法学硕士的免费资源 ","阶段-4模型部署#阶段 4：模型部署":"MLOps，机器学习的部署和生命周期管理：\n基础知识：git\\ github\\ Linux\\容器化\\云，HF Spaces\\ Streamlit Sharing； 部署方式：在线部署：批处理，实时（数据库触发器、发布/订阅、Web 服务、应用内）；离线部署（在本地开发环境、测试环境或内部离线环境中部署批处理，实时处理）； 主要内容：自动化管道，监控，生命周期管理，治理； 核心概念：持续集成与持续部署（CI/CD），版本控制，模型监控； 管理工具：MLFlow，Polyaxon，Metaflow，Kubeflow； 推荐阅读：\n成为 MLOps 工程师所需的唯一免费课程：MLOps Zoomcamp 掌握 MLOps 的 10 个 GitHub 存储库 "},"title":"人工智能"},"/documentation/ai/end_to_end/":{"data":{"":"\n概述人工智能，机器学习，深度学习，统计机器学习等相关概念； 工具Python 中的机器学习；简单有效的预测数据分析工具； 算法了解常用算法原理。了解算法优缺点，原理，应用； 步骤选择并学习一个过程（CRISP-DM）。学习建模分步过程； 自动机器学习python 自动机器学习的常用库概述；可用来快速选择模型\\算法； 大数据集python 处理大数据集的方法； "},"title":"1. 端到端的机器学习"},"/documentation/ai/end_to_end/automl/":{"data":{"":" "},"title":"1.5. 自动 ML"},"/documentation/ai/end_to_end/crisp/":{"data":{"":"","crisp-dm#CRISP-DM":"CRISP-DM（CRoss Industry Standard Process for Data Mining）是数据挖掘领域的标准流程框架，被广泛应用于从数据中发现商业价值的系统化方法。以下是其核心要点：\n1️⃣ 业务/研究理解（定义问题） 首先，根据业务或研究单元，从总体上清楚的阐明项目目标和需求。 然后，将这些目标和约束转换为数据挖掘问题定义的公式。 最后，准备实现这些目标的初步策略。 2️⃣ 数据准备 该阶段需要投入大量的精力，涵盖准备最终数据集的方方面面，这些数据将用于后续阶段，涉及初始数据、原始数据和脏数据。 选择要分析的案例和变量，为分析做好准备工作。 如果需要的话，对确定的变量进行转换。 对原始数据展开清理工作，为使用建模工具建模打下基础。 数据准备可以细分如下\n数据收集 数据初步准备 数据预处理 数据转换 特征构建 特征选择 降维 3️⃣ 数据理解 首先，通过探索性数据分析熟悉数据，发现浅层见解（数据探索，第一步：初步了解数据）。 然后，评估数据质量。 最后，如果需要的话，选择可能包含可执行模式的感兴趣的数据子集。 4️⃣ 建模阶段 选择并应用适当的建模技术。 校准模型设置以优化结果。 通常，对同一个数据挖掘问题坑你要应用多种不同的技术。 可能需要返回数据准备阶段，以便使用数据形式能够符合特定数据挖掘技术对数据的特定需求。 5️⃣ 评估阶段 建模阶段将发布一个或多个模型。在将这些模型部署到现场进行使用前，对模型质量和效果开展评估工作。 同时要确认模型是否能完成阶段1设定的目标。 确认业务或研究问题的重要组成部分是否未被清楚的解释。 最后，做出有关是否使用数据挖掘结果的决定。 6️⃣ 部署阶段 建立了模型并不意味着项目已经完成。需要应用已建立的模型。 简单部署实例：建立报表。 复杂一些的部署实例：在其他部门实现并行数据挖掘过程。 对商业应用来说，客户通常会基于建立的模型开展部署工作。 📝 参考网址\\书籍：\n《数据挖掘与预测分析》 Daniel T. Larose，Chantal D. Larose 官方文档： https://www.datascience-pm.com/crisp-dm-2/ "},"title":"1.4 步骤"},"/documentation/ai/end_to_end/crisp/define_problem/":{"data":{"":"","1定义问题#1、定义问题":" 问题是什么？ 为什么需要解决问题？ 探索如何解决问题？ 1.1、问题是什么？ 简单描述问题; 定义问题目标; (主要目标，次要目标) 解决问题方案; (假设列表，算法列表; 评价指标; 展示方案，……) 查看相似项目; 例如，展示方案如下：\n编写分析报告展示你的结果； 使用 Streamlit 开发一个 demo 展示模型； 部署模型，并托管，监控…… 部署到移动设备，或其他电子元实现智能化 1.2、为什么需要解决问题？ 练习；不需要使用最合适的算法，而是想探索不熟悉的算法，学习新技能； 工作；解决工作中的数据分析问题； 竞赛；获取良好的排名，提升知名度，获取奖金。 1.3、探索如何解决问题？ 现有：逐步列出您将收集哪些数据？\n—\u003e 现有数据范围有多大（存储地址\\数据量）？\n—\u003e 都是什么样的（数据质量）？\n—\u003e 能不能解决我们的问题？\n期望：希望拥有哪些数据？能否获取到这些数据？\n尝试：使用已经收集的数据解决现有问题，验证假设列表；\n📝 参考网址\\书籍：\nhttps://machinelearningmastery.com/how-to-define-your-machine-learning-problem/ 2.1.6、创建数据 通过 Sklearn.datasets 模块的函数可以创建指定类型数据集：\nmake_classification 函数：生成具有特定分类特征和复杂分布的数据集。 make_regression 函数：生成连续目标特征的数据集。 make_blobs 函数：生成简单的聚类型数据集。 make_moons 函数：创建两个交错的半圆数据。 make_circles 函数：在 2d 中画一个大圆，里面包含一个小圆。一个简单的玩具数据集，用于可视化聚类和分类算法。 1️⃣ make_classification 2️⃣ make_regression 3️⃣ make_blobs 4️⃣ make_moons 5️⃣ make_circles 生成具有特定分类特征和复杂分布的数据集。注：make_classification 函数较多，这里简单列举了几个常用的。\n1from sklearn.datasets import make_classification 2 3features, target = make_classification( 4 n_samples = 100 # 生成 100 个样本。 5 ,n_features = 3 # 每个样本有 3 个特征。 6 ,n_informative = 3 # 有 3 个具有信息量的特征，即对区分类别有帮助的特征。 7 ,n_redundant = 0 # 没有冗余特征。 8 ,n_classes = 2 # 生成 2 个类别。 9 ,weights = [.25, .75] # 指定两个类别的样本比例，这里第一个类别的样本占比 25%，第二个类别的样本占比 75%。 10 ,random_state = 1 # 设置随机数种子，以确保结果的可重复性。 11 ) 12 13print(features[0:5],'\\n') 14print(target[0:5]) 生成连续目标特征的数据集。\n1from sklearn.datasets import make_regression 2 3features, target, coefficients = make_regression( 4\tn_samples = 100 # 指定生成的样本数量为 100 个。 5\t,n_features = 3 # 指定数据集的特征数量为 3 个。 6\t,n_informative = 3 # 指定具有实际信息（对预测目标有贡献）的特征数量为 3 个。 7\t,n_targets = 1 # 指定目标变量的数量为 1 个。 8\t,noise = 0.0 # 设置噪声水平为 0，即生成的数据集没有噪声。 9\t,coef = True # 表示返回生成数据的真实系数。 10\t,random_state = 1 # 设置随机数生成器的种子，以确保结果的可重复性。 11\t) 12 13\"\"\" 14参数 noise： 15较小的值（如 0.1、0.5 等）用于模拟适度的噪声， 16较大的值（如 1.0 及以上）则表示较强的噪声干扰。 17\"\"\" 18 19# features ：特征数据 20# target ：目标数据 21# coefficients ：真实的系数 22 23print(features[0:5],'\\n') 24print(target[0:5],'\\n') 25print(coefficients) 生成简单的聚类型数据集。\n1from sklearn.datasets import make_blobs 2 3features, target = make_blobs( 4\tn_samples = 100 # 生成 100 个样本 5\t,n_features = 2 # 每个样本有 2 个特征 6\t,centers = 3 # 指定生成数据的类别数为 3，即会生成围绕 3 个中心点的数据簇；也可以指定具体中心店：centers = [[-2, 2], [2, 2], [0, 4]] 7\t,cluster_std = 0.5 # 每个数据簇的标准差为 0.5，决定了数据的分散程度；可以指定不同标准差：cluster_std=[1.0,3.0] 8\t,shuffle = True\t# 在生成数据后，对数据进行随机打乱。 9\t,random_state = 1 # 置随机数生成器的种子，以保证结果的可重复性。 10\t) 11 12print(features[0:5],'\\n') 13print(target[0:5],'\\n') 绘制创建数据集的散点图：\n1import matplotlib.pyplot as plt 2 3fig, ax = plt.subplots(figsize=(3, 3)) 4 5ax.scatter( 6 features[:, 0] 7 , features[:, 1] 8 , c=target 9 , cmap='viridis' 10 ) 11 12plt.show() 创建两个交错的半圆数据。\n1from sklearn.datasets import make_moons 2 3features, target = make_moons( 4\tn_samples=500 # 指定生成的样本总数。 5\t, noise=0.2 # 添加的噪声标准差。 6 , shuffle=True # 如果为True，则打乱样本顺序。 7\t, random_state=0 # 设置随机种子为 0 以确保可重复性 8\t) 9 10print(features[0:5],'\\n') 11print(target[0:5],'\\n') 绘制创建数据集的散点图：\n1import matplotlib.pyplot as plt 2 3fig, ax = plt.subplots(figsize=(3, 3)) 4 5ax.scatter( 6 features[:, 0] 7 , features[:, 1] 8 , c=target 9 , cmap='viridis' 10 ) 11 12plt.show() 在 2d 中画一个大圆，里面包含一个小圆。一个简单的玩具数据集，用于可视化聚类和分类算法。\n1from sklearn.datasets import make_circles 2 3features, target = make_circles( 4\tn_samples=500 # 指定生成的样本总数。 5\t, noise=0.2 # 添加的噪声标准差。可以使生成的同心圆形状不那么规则，更接近真实世界的数据情况。 6 , shuffle=True # 如果为True，则打乱样本顺序。随机打乱生成的数据集的顺序。 7\t, random_state=0 # 设置随机种子为 0 以确保可重复性 8 , factor=0.4 # 内圆与外圆之间的比例因子。控制两个同心圆之间的距离大小。 9\t) 10 11print(features[0:5],'\\n') 12print(target[0:5],'\\n') 绘制创建数据集的散点图：\n1import matplotlib.pyplot as plt 2 3fig, ax = plt.subplots(figsize=(3, 3)) 4 5ax.scatter( 6 features[:, 0] 7 , features[:, 1] 8 , c=target 9 , cmap='viridis' 10 ) 11 12plt.show() 2.1.7、导出数据 1️⃣ 数据库 （1）将 Pandas 数据框导入 MySQL\n使用 python pandas 生成一个数据框。\n1import pandas as pd 2import numpy as np 3import random 4 5cities = ['北京', '上海', '广州', '深圳', '成都'] 6address_samples = ['中山路{}号'.format(i) for i in range(1000)] 7 8data = { 9 'id': range(1, 101), 10 'city': [random.choice(cities) for _ in range(100)], 11 'address': [random.choice(address_samples) for _ in range(100)], 12 'price': np.random.randint(1000000, 10000000, 100) 13} 14 15df = pd.DataFrame(data) 16 17df.head() 使用 python sqlalchemy 库将生成的数据直接写入 MySQL。\n1from sqlalchemy import create_engine 2import sqlalchemy 3 4engine = create_engine('mysql+pymysql://root:123456@localhost:3306/test') 5 6df.to_sql( 'housing_price' # 数据库表名 7 , con=engine 8 , index=False 9 , if_exists='replace' # 如果表已经存在，它会被替换 10 , dtype={ 11 'id': sqlalchemy.types.INT 12 ,'city': sqlalchemy.types.NVARCHAR(length=10) 13 ,'address': sqlalchemy.types.NVARCHAR(length=40) 14 ,'price': sqlalchemy.types.DECIMAL(15, 3) 15 } 16) A B C D 2013-01-01 $-0.29 $0.23 $0.01 $1.61 2013-01-02 $-0.04 $0.03 $-0.63 $0.51 2013-01-03 $0.22 $-0.90 $-0.15 $0.71 A B C D 2013-01-01 $-0.29 $0.23 $0.01 $1.61 2013-01-02 $-0.04 $0.03 $-0.63 $0.51 2013-01-03 $0.22 $-0.90 $-0.15 $0.71 "},"title":"1️⃣ 定义问题"},"/documentation/ai/end_to_end/crisp/preparation/collect_data/":{"data":{"":"","1数据收集#1、数据收集":"1、数据收集 1.1、数据来源 数据文件： 这是存储数据的常见形式，例如 CSV（逗号分隔值）文件、Excel 文件、JSON 文件、XML 文件等。数据文件通常以结构化或半结构化的方式组织数据，可以通过读取文件的方式将数据导入到应用程序或分析工具中。 数据库： 是专门用于存储和管理数据的系统，如关系型数据库（如 MySQL、Oracle、SQL Server 等）和非关系型数据库（如 MongoDB、Cassandra 等）。数据库提供了高效的数据存储、检索、更新和管理功能，并支持复杂的查询和事务处理。 …… 1.2、选择数据 选择将要使用的所有可用数据的子集。需要考虑实际需要哪些数据来解决您正在处理的问题或难题。对所需的数据进行一些假设，并小心记录这些假设，以便以后可以在需要时对其进行测试。\n以下是一些问题，可帮助您思考整个过程：\n您拥有的数据范围有多大？例如，申请使用通过时间，数据库表数量，连接的系统。确保您对可以使用的所有内容都有清晰的了解。 哪些数据不可用，而您希望您有这些数据？例如，未记录或无法记录的数据。您可以派生或模拟此数据。 您不需要哪些数据来解决问题？排除数据几乎总是比包含数据更容易。记下您排除了哪些数据及其原因。 只有在小问题中，例如竞赛或玩具数据集，数据已经为您选择了。 您选择的数据可能格式不适合使用。数据可能位于关系数据库中，您希望它位于平面文件中，或者数据可能采用专有文件格式。 1.3、工作空间 工作空间可以理解为数据科学项目的目录结构\\项目模板。以下是创建工作空间的两个 python 案例：\n（1）创建工作空间案例 1：\n1import os 2object_name = 'Kaggle_001_Object-name' 3 if object_name not in os.listdir(): 4 os.mkdir(object_name) 5 os.mkdir(object_name+'/input') 6 os.mkdir(object_name+'/src') 7 os.mkdir(object_name+'/models') 8 os.mkdir(object_name+'/notebooks') 9 open(object_name+'/README.md','w') 10 open(object_name+'/LICENSE','w') 11 else: 12 print(object_name + ' is OK!') （2）创建工作空间案例 2：\n1import os 2 3project_name = 'Kaggle_002_class-name' 4folder_name = ['input', 'src', 'models', 'notebooks'] 5file_name = ['README.md', 'LICENSE'] 6file_list = os.listdir() 7 8if project_name not in file_list: 9 10 # （1）、如果该空间不存在则创建工作空间 11 os.mkdir(project_name) 12 13 # （2）、创建文件夹：'input', 'src', 'models', 'notebooks' 14 for i in folder_name: 15 path_folder = os.path.join(project_name, i) 16 os.mkdir(path_folder) 17 18 # （3）、创建文件：'README.md', 'LICENSE' 19 for j in file_name: 20 path_file = os.path.join(project_name, j) 21 open(path_file, 'w', encoding='utf-8') 22 23 print(project_name + ' is OK!') 24 25else: 26 print(project_name + ' is OK!') 📝 参考网址\\书籍：\n《Approaching (Almost) Any Machine Learning Problem》 Abhishek Thakur\n1.4、显示设置\\库版本 1️⃣ 查看库版本 （1）%load_ext watermark 查看库版本：\n1# 在 jupyter lab 执行以下代码 2! pip install watermark Requirement already satisfied: watermark in f:\\anaconda3\\lib\\site-packages (2.5.0) Requirement already satisfied: ipython\u003e=6.0 in f:\\anaconda3\\lib\\site-packages (from watermark) (8.27.0) Requirement already satisfied: importlib-metadata\u003e=1.4 in f:\\anaconda3\\lib\\site-packages (from watermark) (7.0.1) Requirement already satisfied: setuptools in f:\\anaconda3\\lib\\site-packages (from watermark) (75.1.0) Requirement already satisfied: zipp\u003e=0.5 in f:\\anaconda3\\lib\\site-packages (from importlib-metadata\u003e=1.4-\u003ewatermark) (3.17.0) Requirement already satisfied: decorator in f:\\anaconda3\\lib\\site-packages (from ipython\u003e=6.0-\u003ewatermark) (5.1.1) Requirement already satisfied: jedi\u003e=0.16 in f:\\anaconda3\\lib\\site-packages (from ipython\u003e=6.0-\u003ewatermark) (0.19.1) Requirement already satisfied: matplotlib-inline in f:\\anaconda3\\lib\\site-packages (from ipython\u003e=6.0-\u003ewatermark) (0.1.6) Requirement already satisfied: prompt-toolkit\u003c3.1.0,\u003e=3.0.41 in f:\\anaconda3\\lib\\site-packages (from ipython\u003e=6.0-\u003ewatermark) (3.0.43) Requirement already satisfied: pygments\u003e=2.4.0 in f:\\anaconda3\\lib\\site-packages (from ipython\u003e=6.0-\u003ewatermark) (2.15.1) Requirement already satisfied: stack-data in f:\\anaconda3\\lib\\site-packages (from ipython\u003e=6.0-\u003ewatermark) (0.2.0) Requirement already satisfied: traitlets\u003e=5.13.0 in f:\\anaconda3\\lib\\site-packages (from ipython\u003e=6.0-\u003ewatermark) (5.14.3) Requirement already satisfied: colorama in f:\\anaconda3\\lib\\site-packages (from ipython\u003e=6.0-\u003ewatermark) (0.4.6) Requirement already satisfied: parso\u003c0.9.0,\u003e=0.8.3 in f:\\anaconda3\\lib\\site-packages (from jedi\u003e=0.16-\u003eipython\u003e=6.0-\u003ewatermark) (0.8.3) Requirement already satisfied: wcwidth in f:\\anaconda3\\lib\\site-packages (from prompt-toolkit\u003c3.1.0,\u003e=3.0.41-\u003eipython\u003e=6.0-\u003ewatermark) (0.2.5) Requirement already satisfied: executing in f:\\anaconda3\\lib\\site-packages (from stack-data-\u003eipython\u003e=6.0-\u003ewatermark) (0.8.3) Requirement already satisfied: asttokens in f:\\anaconda3\\lib\\site-packages (from stack-data-\u003eipython\u003e=6.0-\u003ewatermark) (2.0.5) Requirement already satisfied: pure-eval in f:\\anaconda3\\lib\\site-packages (from stack-data-\u003eipython\u003e=6.0-\u003ewatermark) (0.2.2) Requirement already satisfied: six in f:\\anaconda3\\lib\\site-packages (from asttokens-\u003estack-data-\u003eipython\u003e=6.0-\u003ewatermark) (1.16.0) 1# 在 jupyter lab 执行以下代码查看库版本 2# 需要先安装 watermark 库 3# numpy,pandas,matplotlib,sklearn,seaborn version 4%load_ext watermark 5%watermark -a \"Sebastian Raschka\" -u -d -v -p\\ 6numpy,pandas,matplotlib,sklearn,seaborn The watermark extension is already loaded. To reload it, use: %reload_ext watermark Author: Sebastian Raschka Last updated: 2025-07-27\nPython implementation: CPython Python version : 3.12.7 IPython version : 8.27.0\nnumpy : 1.26.4 pandas : 2.2.2 matplotlib: 3.9.2 sklearn : 1.5.1 seaborn : 0.13.2\n（2）xxx.\\_\\_version\\_\\_ 查看库版本：\n1# 在 jupyter lab 执行以下代码查看 pandas 版本 2import pandas 3print('pandas: {}'.format(pandas.__version__)) pandas: 2.2.2 （3）!python --version 查看 python 版本：\n1# 在 jupyter lab 执行以下代码查看 python 版本 2!python --version Python 3.12.7 2️⃣ 显示设置 这里介绍的显示设置主要是关于 pandas 数据框，numpy 数组，matplotlib 的一些常规显示设置 。如，小数位数，matplotlib 主题等，主要是在 jupyter lab 中展示时需要设置。\n1# （1）禁止显示不需要的警告 2# ------------------------- 3import warnings 4warnings.filterwarnings(\"ignore\") 5 6 7# （2）pandas 设置 8# ------------------------- 9 10pd.set_option('display.max_info_columns',200) # info()变量最多显示200个 11pd.set_option('display.max_info_rows',200) # info()缺失值个数上限 12 13pd.set_option('display.float_format','${:,.2f}'.format) # 显示格式 $0.67 14pd.set_option('display.unicode.east_asian_width', False) # 设置输出右对齐，此代码写入脚本中 15pd.set_option('display.precision',4) # 保留4位小数 16pd.set_option('precision', 3) # 保留3位小数 17pd.set_option('display.chop_threshold',0.5) # 绝对值小于 0.5 显示 0 18 19pd.set_option('display.max_rows',5) # 设置显示数据框行数 20pd.set_option('display.max_columns',100) # 设置显示数据框列数 21pd.set_option('display.max_colwidth',200) # 设置显示数据框列宽 22pd.options.display.max_colwidth = 80 # 设置显示数据框列宽 23pd.options.display.max_columns = 20 # 设置显示数据框列数 24pd.options.display.max_rows = 20 # 设置显示数据框行数 25 26pd.set_option('display.colheader_justify', 'left') # 确保列名不换行 27 28 29# （3）matplotlib 设置 30# ------------------------- 31plt.rcParams['font.sans-serif']=['FangSong'] # 替换sans-serif字体，正常显示中文(黑体)\\'SimHei'\\'FangSong' 32plt.rcParams[\"font.weight\"] = \"bold\" # 字体加粗 33plt.rcParams['axes.unicode_minus'] = False # 坐标显示负号 34plt.rcParams['savefig.dpi'] = 1000 # 图片像素 35plt.rcParams['figure.dpi'] = 100 # 分辨率（不常用） 36 37plt.style.use('classic') # 设置绘图风格'ggplot'\\'classic' 38matplotlib.rcdefaults() # 使用默认绘图风格 39 40 41# （4）numpy 设置 42# ------------------------- 43np.set_printoptions(precision=3, suppress=True) # precision：保留几位小数，后面不会补0，supress=True：对很大/小的数不使用科学计数法 44np.set_printoptions(formatter={'float': '{: 0.3f}'.format}) # formatter：强制格式化，后面会补0 \u003e 设置案例 1import numpy as np 2 3# 创建三个随机小数 4random_floats = np.random.rand(3) 5print(random_floats) [ 0.817 0.166 0.870] 1# formatter：强制格式化，后面会补0 2np.set_printoptions( 3 formatter={'float': '{: 0.3f}'.format} 4 ) 5 6print(random_floats) [ 0.817 0.166 0.870] 1import pandas as pd 2# 将列表转换为数据框 3pd.DataFrame(random_floats) 0 0 $0.82 1 $0.17 2 $0.87 0 0 $0.82 1 $0.17 2 $0.87 1import pandas as pd 2 3# 保留3位小数 4pd.set_option('display.precision',3) 5pd.DataFrame(random_floats) 0 0 $0.82 1 $0.17 2 $0.87 0 0 $0.82 1 $0.17 2 $0.87 1import pandas as pd 2 3# 显示格式 $0.67 4pd.set_option('display.float_format','${:,.2f}'.format) 5pd.DataFrame(random_floats) 0 0 $0.82 1 $0.17 2 $0.87 0 0 $0.82 1 $0.17 2 $0.87 1.5、导入数据 1️⃣ pd.DataFrame() \u003e 字典 通过 pd.DataFrame() 函数将字典转换为数据框格式:\n1import numpy as np 2import pandas as pd 3 4directory = { 5 \"A\": 1.0, 6 \"B\": pd.Timestamp(\"20130102\"), 7 \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"), 8 \"D\": np.array([3] * 4, dtype=\"int32\"), 9 \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]), 10 \"F\": \"foo\", 11} 12 13df2 = pd.DataFrame(directory) 14df2 A B C D E F 0 1.0 2013-01-02 1.0 3 test foo 1 1.0 2013-01-02 1.0 3 train foo 2 1.0 2013-01-02 1.0 3 test foo 3 1.0 2013-01-02 1.0 3 train foo A B C D E F 0 1.0 2013-01-02 1.0 3 test foo 1 1.0 2013-01-02 1.0 3 train foo 2 1.0 2013-01-02 1.0 3 test foo 3 1.0 2013-01-02 1.0 3 train foo \u003e 列表 通过 pd.DataFrame() 函数将列表转换为数据框格式。\n1import numpy as np 2import pandas as pd 3 4dates = pd.date_range(\"20130101\", periods=6) 5 6df = pd.DataFrame( 7 np.random.randn(6, 4) 8 ,index=dates 9 ,columns=list(\"ABCD\") 10 ) 11 12df.head() A B C D 2013-01-01 -2.583607 0.294989 1.763537 0.692427 2013-01-02 0.377671 -0.261353 -0.126769 -0.690070 2013-01-03 0.917019 -0.054316 0.079361 0.031414 2013-01-04 0.650100 -1.334884 1.409406 1.739485 2013-01-05 -0.334454 -0.370423 -0.822672 -0.809271 A B C D 2013-01-01 -2.583607 0.294989 1.763537 0.692427 2013-01-02 0.377671 -0.261353 -0.126769 -0.690070 2013-01-03 0.917019 -0.054316 0.079361 0.031414 2013-01-04 0.650100 -1.334884 1.409406 1.739485 2013-01-05 -0.334454 -0.370423 -0.822672 -0.809271 2️⃣ Sklearn.datasets Sklearn 库自带数据集：\n数据集 数据集描述 load_iris 鸢尾花数据集（分类） load_diabetes 糖尿病数据集（回归） load_digits 数字数据集（分类） load_linnerud 体力锻炼 Linnerud 数据集 load_wine 葡萄酒数据集（分类） load_breast_cancer 威斯康星州乳腺癌数据集（分类） 案例：查看鸢尾花分类数据集\n1# 导入 sklearn.datasets 数据集 2from sklearn import datasets 3 4# 导入鸢尾花分类数据集 5iris = datasets.load_iris() 6 7# 打印数据描述 8#print(iris.DESCR) 9 10# 打印数据字典中的关键字 11print('---------- iris.keys() ----------') 12print(iris.keys(), '\\n') 13 14# 特征值 15features = iris.data 16print('---------- features[0:10] ----------') 17print(features[0:10], '\\n') 18 19# 标签值 20target = iris.target 21print('---------- target[0:10] ----------') 22print(target[0:10], '\\n') 23 24# 特征名称 25feature_names = iris.feature_names 26print('---------- feature_names ----------') 27print(feature_names, '\\n') 28 29# 标签名称 30target_names = iris.target_names 31print('---------- target_names ----------') 32print(target_names, '\\n') ---------- iris.keys() ---------- dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module']) ———- features[0:10] ———- [[5.1 3.5 1.4 0.2] [4.9 3. 1.4 0.2] [4.7 3.2 1.3 0.2] [4.6 3.1 1.5 0.2] [5. 3.6 1.4 0.2] [5.4 3.9 1.7 0.4] [4.6 3.4 1.4 0.3] [5. 3.4 1.5 0.2] [4.4 2.9 1.4 0.2] [4.9 3.1 1.5 0.1]]\n———- target[0:10] ———- [0 0 0 0 0 0 0 0 0 0]\n———- feature_names ———- ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n———- target_names ———- ['setosa' 'versicolor' 'virginica']\n3️⃣ .csv \u003e pd.read_csv() 1import pandas as pd 2 3df = pd.read_csv( 4 'PATH/file_name' # 文件名称 5 ,header=0 # 设置第一行为列名称 6 ,names=['','','',...] # header=None 时，设置列名 7 ,sep=',' # 设置分隔符 8 ,na_values=[':', ' '] # 不可用字符/标记为缺失值的字符 9 ,usecols=['', '', ''] # 需要的列 10 ,delim_whitespace=True # 默认 False 是否指定空格(\" \"或\"\\t\")为分隔符使用，等效于设定sep='\\s+'。 11 ) 1# 读取 kaggle 泰坦尼克号数据集 2 3import pandas as pd 4 5df = pd.read_csv( 6 'datasets/titanic/train.csv' # 文件名称 7 ,header=0 # 设置第一行为列名称 8 ) 9 10# 产看前 3 行，前 4 列 11df.iloc[:3,0:4] \u003e open()+csv.read() 1import numpy as np 2import pandas as pd 3import csv 4import os 5 6# 数据集文件的路径，'datasets/titanic'是文件夹名，\"train.csv\"是文件名 7data_filename = os.path.join( 8 'datasets' 9 , 'titanic' 10 , 'train.csv' 11 ) 12 13# 用 csv 模块来导入数据集文件，并创建 csv 阅读器对象 14with open(data_filename, 'r') as input_file: 15 # 创建一个 CSV 读取器对象，用于读取数据文件 16 reader = csv.reader(input_file) 17 # 将读取到的 CSV 数据转换为列表形式并存储在 iris_data 变量中 18 data = list(reader) 19 20# 查看前 3 行，前 4 列 21pd.DataFrame(data).iloc[:3,0:4] 4️⃣ .xlsx \u003e pd.read_excel() 1import pandas as pd 2 3df = pd.read_excel( 4 'datasets/titanic/train.xlsx' # 文件名称 5 ,sheet_name='train' 6 ,header=0 # 设置第一行为列名称 7 ) 8 9# 查看前 3 行，前 4 列 10df.iloc[:3,0:4] 5️⃣ Database \u003e MySql 使用 pymysql 链接数据库，并使用 pd.read_sql 读取数据。\n1# 禁止显示不需要的警告 2import warnings 3warnings.filterwarnings(\"ignore\") 4 5sql_student = \"SELECT * FROM student\" 6sql_score = \"SELECT * FROM score\" 7sql_teacher = \"SELECT * FROM teacher\" 8sql_course = \"SELECT * FROM course\" 9 10# 导入库 11import pymysql 12import pandas as pd 13 14conn = pymysql.connect( 15 host='localhost' 16 ,user='root' 17 ,password = \"000000\" 18 ,db='test' 19) 20 21df_student = pd.read_sql( 22 sql_student # 23 ,conn 24 ) 25 26df_student.head() 1.6、创建数据 "},"title":"2-1 收集数据"},"/documentation/ai/end_to_end/overview/":{"data":{"":"","1人工智能概述#\u003cfont face=Georgia\u003e1、人工智能概述\u003c/font\u003e":"1.1、相关概念 人工智能\n可以像人类一样学习、理解、思考的计算机程序； 机器学习\n人工智能的一个子集。使用数据训练模型，这些模型可以根据在数据中找到的关系进行预测； 深度学习\n机器学习的一个分支。使用特殊分层结构的机器学习方法（这些分层依次堆叠）；\n深度学习算法，受到大脑结构的启发，可以很好地处理图像、视频或文本等非结构化数据；\n深度学习框架，是一个拼凑了层和函数等组件的库。是一种具有求导功能的编程语言（“可微分编程语言”）；\n自然语言，让计算机理解、分析和生成人类自然语言；\n计算机视觉，让计算机理解和处理图像及视频信息； 生成式人工智能\n可以生成以前从未见过的新内容，如文本，图像，视频等；\n自然语言方向，计算机视觉方向； 1.2、人工智能简史 19 世纪 30~40 年代 —— 分析机（Analytical Engine） 1️⃣ 查尔斯 • 巴贝奇 —— 分析机（Analytical Engine）理念\n查尔斯·巴贝奇从 1834 年开始设计分析机。分析机被认为是现代计算机的先驱，它具有很多现代计算机的特征，如存储程序、通用计算等理念。 2️⃣ 霍华德·艾肯（Howard Aiken）团队 —— 马克一号（Mark I）\n它是 1944 年制造出的一种电动机械计算机，能够进行各种复杂的数学计算，被认为是 第一台通用的机械式计算机。它的用途仅仅是利用机械操作将数学分析领域的某些计算自动化，因此得名“分析机”。 3️⃣ 沃伦·麦卡洛克（Warren McCulloch）,沃尔特·皮茨（Walter Pitts） —— 神经元的数学模型\n1943 年提出了一种形式神经元的数学模型，被认为是 最早的神经网络模型之一。 20 世纪 50 年代 —— 符号主义人工智能（symbolic AI） 1️⃣ 符号主义人工智能（symbolic AI）\n精心编写足够多的明确规则来处理知识，就可以实现与人类水平相当的人工智能。 2️⃣ 阿兰 • 图灵 —— “图灵测试”\n人工智能先驱阿兰 • 图灵在其 1950年发表的具有里程碑意义的论文“计算机器和智能”。 在这篇论文中，图灵提出了著名的“图灵测试”，用于判断机器是否具有智能。他认为如果一台机器能够与人类进行对话而不被人类察觉出其为机器，那么就可以认为这台机器具有智能。这篇论文为人工智能的发展奠定了重要的理论基础。 3️⃣ 弗兰克·罗森布拉特（Frank Rosenblatt） —— 感知机\n1957 年美国心理学家弗兰克·罗森布拉特（Frank Rosenblatt）提出感知机。它是一种简单的二分类线性分类模型，它是神经网络和支持向量机的基础。 感知机的提出在当时引起了很大的轰动，但后来人们发现它只能处理线性可分的问题，具有一定的局限性。不过，感知机的出现为后来更复杂的神经网络的发展奠定了基础。 20 世纪 60 ~ 70年代初 —— 第一次冬天 计算能力的限制 和 数据的缺乏，机器学习的发展陷入了瓶颈。\n过高的期望未能实现，研究人员和政府资金均转向其他领域。 20 世纪 80 年代 —— 专家系统（expert system） 专家系统 使得符号主义人工智能热度达到了顶峰。 20 世纪 90 年代初 —— 第二次冬天 专家系统 维护费用变得很高，难于扩展，并且使用范围有限，人们逐渐对其失去兴趣。 20 世纪 90 年代 —— 机器学习 专家系统难于给出明确的规则来解决更加复杂、模糊的问题，比如图像分类、语音识别、和语言翻译。 于是 20 世纪 90 年代出现了 机器学习 来替代符号人工智能。 机器学习是训练出来的，而不是明确规地用程序编写出来的。 21 世纪 20 年代 —— 生成式人工智能 OpenAI 在2020年6月发布了 GPT-3，这是一个非常大且复杂的模型，拥有 1750亿个参数。 GPT-3 在生成文本和其他语言任务方面的表现令人瞩目，并且激发了大量关于 AI 的讨论。 ","2机器学习#\u003cfont face=Georgia\u003e2、机器学习\u003c/font\u003e":"2.1、概述 机器学习 是一门多领域学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。 机器学习 主要是设计和分析一些让计算机可以自动“学习”的算法。 机器学习算法 是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。 由于学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为 统计机器学习。 2.2、分类 1️⃣ 监督学习 监督学习：从有标注（标签\\标记）的数据中学习预测模型的机器学习问题；\n监督学习主要任务 —— 分类、回归； 分类任务： 将实例数据划分到预设的某些类别中，是一种离散型预测。如，判断一封电子邮件是不是垃圾邮件；\n回归任务： 用于预测连续值。比如预测房价，股票价格等；\n生成模型 \\ 判别模型： 生成模型 \\ 判别模型： 监督学习的任务就是学习一个模型，应用这个模型，对给定的输入预测相应的输出。\n这个模型的一般形式为决策函数（判别模型 ）： $$Y = f(X)$$ 或者条件概率分布（生成模型）： $$Y = P(Y|X)$$\n判别模型：在已知输入的情况下，预测出输出，常见的判别模型有逻辑回归、支持向量机和深度学习神经网络等。\n生成模型：尝试捕捉数据中的潜在分布，常见的生成模型有高斯混合模型和朴素贝叶斯分类器等。 2️⃣ 无监督学习 无监督学习：从无标注（标签\\标记）的、或结构未知的数据中学习预测模型的机器学习问题；\n这种学习方式的目标通常是为了探索数据，找出其中的结构或者模式；\n无监督学习主要任务 —— 聚类、降维、异常检测、关联规则 聚类：目标是发现并识别数据中的自然分组。是构造信息和从数据中导出有意义关系的一种有用的技术； 例如，将客户分为几个群体进行市场细分；为分析过程中出现的每个群定义一组对象，\n它们之间都具有一定程度的相似性，但与其他群中对象的差异性更大；\n降维：特征预处理中数据去噪的一种常用方法，这个过程叫作特征提取。目标是在不丢失太多信息的前提下简化数据； 将多个相关特征合并为一个。降低了某些算法对预测性能的要求，\n并在保留大部分相关信息的同时将数据压缩到较小维数的子空间上。\n案例：汽车的里程与其使用年限存在很大的相关性，所以降维算法会将它们合并成一个代表汽车磨损的特征。\n这个过程叫作特征提取。\n异常检测：异常检测的目标是检测出不符合其他正常数据行为的数据点； 比如，检测信用卡交易中的欺诈行为；\n关联规则：挖掘大量数据，发现属性之间的有趣联系； 比如，在超市销售日志上运行关联规则之后发现买烧烤酱和薯片的人也倾向于购买牛排。那么，可以将这几样商品摆放得更近一些；\n3️⃣ 半监督学习 半监督学习：半监督学习：利用少量的有标注数据和大量的无标注数据来进行学习。在只有少量标注数据的情况下，通过利用大量的无标注数据，可以提高机器学习模型的性能和泛化能力。大多数半监督式学习算法是无监督式和监督式算法的结合。\n例如，在图像分类任务中，如果只有少量标注过的图片（比如只有几百张标有 “猫”“狗”“鸟” 的图片），但同时有大量未标注的图片，半监督式学习算法就可以先通过无监督学习从这些未标注的图片中提取一些通用的图像特征，然后再利用少量标注过的图片进行监督学习，调整模型参数，从而提高分类的准确性。\n学习过程： 首先，半监督学习算法会利用少量的有标注数据来建立一个初步的模型。 然后，半监督学习算法会利用大量的无标注数据来进一步改进和优化模型。无标注数据虽然没有明确的类别或目标值信息，但是它们可以提供关于数据分布和潜在结构的信息。 学习方法： 自我训练：一种常见的方法是自我训练。算法首先使用有标注数据训练一个模型，然后用这个模型对无标注数据进行预测，将预测结果比较有把握的无标注数据加入到有标注数据集中，再次训练模型。这个过程不断重复，直到模型性能不再提高或者达到一定的迭代次数。 生成模型：另一种方法是使用生成模型。生成模型可以学习数据的分布，然后根据这个分布生成新的数据或者对无标注数据进行标注。例如，在图像生成任务中，生成对抗网络（GAN）可以学习图像的分布，然后生成新的图像。在半监督学习中，生成模型可以利用无标注数据来学习数据的分布，然后帮助分类器更好地对有标注数据进行分类。 4️⃣ 强化学习 强化学习：智能系统在与环境的连续互动中学习最有行为策略的机器学习问题；\n它的学习系统（在其语境中称为智能体）能够观察环境，做出选择，执行操作，并获得回报（reward），或者是以负面回报的形式获得惩罚； 它必须自行学习什么是最好的策略（policy），从而随着时间推移获得最大的回报。策略代表智能体在特定情况下应该选择的操作。； 强化学习可以被认为是一种自学习的方法。 例如，许多机器人通过强化学习算法来学习如何行走； 5️⃣ 主动学习 主动学习： 在训练过程中为模型提供部分数据标签；模型可以选择它认为最需要标签的数据进行标记，从而提高学习效率。\n算法可以主动地选择它想学习的样本，而不是用全部数据进行训练的算法。 如果允许学习系统选择它自己的训练集，可能会提高学习的效率和效果。 它通常用于样本标签成本高、标签难以获得，而未标注样本充足的场景。 主动学习可以有效地选择最具信息量、对当前模型最有帮助的样本进行标注，从而减少标注的代价。 例如，在只有少量标注图像的情况下，可以通过主动学习选择最有代表性的图像进行标注，提高图像分类的准确性。在医学领域，标注大量的医疗数据是非常昂贵的。主动学习可以选择那些最具诊断价值的数据进行标注，帮助医生提高诊断准确性。\n选择哪些未标注数据进行标注是主动学习的关键。常见策略如下： 1️⃣ 估计标注某个数据点后模型的变化程度，选择那些预计会使模型变化最大的数据进行标注。\n高效利用标注资源：如果标注一个数据点后能使模型发生较大变化，说明这个数据点携带了丰富的信息，对模型的优化具有重要意义。通过选择这样的数据进行标注，可以用较少的标注成本获得较大的模型性能提升。避免浪费标注资源在那些对模型影响较小的数据上，从而提高标注的效率和效果。 加速模型收敛：模型变化程度大的数据点往往能够引导模型更快地朝着更优的方向进行调整和收敛。这些数据点可能揭示了模型当前的不足之处，通过标注它们并将其纳入训练，可以促使模型更快地适应数据的分布，提高模型的准确性和泛化能力。 2️⃣ 使用多个不同的模型对未标注数据进行预测，选择那些分歧最大的数据进行标注。\n探索数据的不确定性：不同的模型可能从不同的角度看待数据，当多个模型对某个数据点的预测存在较大分歧时，说明这个数据点具有较高的不确定性。这种不确定性可能源于数据的复杂性、噪声或者数据处于不同类别之间的边界区域。标注这样的数据可以帮助模型更好地理解这些不确定区域，减少模型的模糊性，提高模型在复杂情况下的决策能力。 集成多个模型的优势：通过选择分歧最大的数据进行标注，可以综合多个模型的观点，充分发挥不同模型的优势。当这些数据被标注后加入训练集，可以促使各个模型之间进行相互学习和调整，从而提高整个模型集成的性能。 3️⃣ 选择那些模型对其预测最不确定的数据进行标注。例如，对于分类问题，可以选择那些模型预测概率最接近 0.5 的数据点。\n聚焦难以判断的数据：预测概率接近 0.5 的数据点意味着模型对其所属类别难以确定。这些数据点通常处于不同类别之间的边界或者具有一些模糊的特征，对于模型来说是具有挑战性的。标注这些数据可以帮助模型更好地学习边界情况和模糊特征，提高模型在分类边界上的准确性，减少错误分类的发生。 高降低模型的风险：如果模型对某些数据过于自信地做出错误预测，可能会导致严重的后果。通过选择不确定的数据进行标注，可以让模型更加谨慎地对待各种情况，降低模型的风险。同时，也可以避免模型过度拟合某些特定的数据模式，提高模型的泛化能力。 6️⃣ 自学习 自学习（Self-training）： 自监督学习是通过自动从数据本身中生成监督信号来进行学习。是指系统能够自主地进行学习和改进的过程。这是一个更加广泛的概念，它涵盖了多种机器学习算法（监督\\无监督\\强化等）。\n这种方法的基本思想是先使用已有的标签数据训练出一个初步的模型，然后用这个模型预测未标签数据，把预测结果作为标签，再和原有标签数据一起重新训练模型。这个过程可以重复进行直到模型收敛。 如果在自学习的过程中，既使用了少量有标注的数据，又利用了大量无标注的数据来提升学习效果，那么此时的自学习可以被认为是采用了半监督学习的方法。 自学习也可以完全基于有监督学习（只使用有标注数据不断改进）或者无监督学习（仅从无标注数据中发现模式）。 例如，自动驾驶汽车、智能机器人、语音识别系统等都需要具备自学习能力，才能不断地提高自己的性能和适应不同的环境。自学习的数据挖掘算法可以自动地从大量数据中挖掘出有价值的信息，为企业决策提供支持。 实现方法： 1️⃣ 机器学习算法 ：自学习系统通常采用机器学习算法，如深度学习、强化学习等，来实现自主学习和改进。这些算法可以通过对大量数据的学习，自动地提取特征、建立模型，并进行预测和决策。\n2️⃣ 反馈机制 ：自学习系统需要建立有效的反馈机制，以便能够根据环境的反馈和自身的表现进行调整和优化。例如，一个自学习的智能机器人可以通过传感器获取环境的反馈信息，然后根据这些信息调整自己的行为策略。\n3️⃣ 数据驱动 ：自学习系统通常是数据驱动的，需要大量的数据来进行学习和训练。这些数据可以来自于各种来源，如传感器、网络、数据库等。\n7️⃣ 多视图学习 多视图学习（Multi-view learning）： 是一种机器学习方法，主要用于处理具有多个不同视角或特征表示的数据。\n在多视图学习中我们假设数据是由多个视图或者说多个不同的特征集生成的，每个视图都可以进行学习和推断，不同视图之间的一致性被用作一种约束以引导学习过程。 多视图：假设我们有一个物体，从不同的角度去观察它，会得到不同的视图。例如，对于一个苹果，从正面看、侧面看、上面看会有不同的样子。在机器学习中，数据也可以有多个视图。比如一张图片可以有颜色特征、纹理特征、形状特征等不同的视图。 学习过程： 1️⃣ 数据表示 ：多视图学习首先要将数据表示为多个视图的形式。每个视图可以是不同类型的特征或者从不同角度提取的信息。例如，在图像分类任务中，一个视图可以是图像的颜色直方图，另一个视图可以是图像的纹理特征矩阵。\n2️⃣ 协同学习 ：多视图学习的核心是让不同的视图相互协作，共同学习一个更好的模型。这就像多个专家从不同的角度一起讨论问题，最终得出一个更全面、更准确的结论。不同视图之间可以通过信息共享、互补学习等方式来提高学习效果。\n信息共享 ：各个视图可以共享一些共同的信息，例如在文档分类中，不同的主题特征视图可能会共享一些常见的关键词信息。通过共享信息，不同视图可以相互补充，提高对数据的理解和建模能力。\n互补学习 ：不同视图也可以从不同的方面捕捉数据的特征，从而实现互补学习。比如在图像识别中，颜色视图可能更擅长区分不同颜色的物体，而形状视图可能更擅长区分不同形状的物体。通过结合这两个视图，模型可以更好地识别各种图像。\n3️⃣ 模型融合 ：在多视图学习的最后阶段，通常需要将不同视图学习到的模型进行融合，得到一个最终的预测结果。融合的方法可以有很多种，比如简单的投票法、加权平均法，或者更复杂的基于深度学习的融合方法。\n8️⃣ 生成模型 生成模型（Generative models）： 是一种机器学习模型，它的目标是学习数据的分布，以便能够生成与训练数据相似的新数据样本。\n生成模型通过学习训练数据的概率分布来实现生成新数据的目的。 尝试估计数据的联合概率分布 ，其中 表示数据的特征向量。一旦生成模型学习到了数据的分布，它就可以通过从这个分布中采样来生成新的数据样本。 例如，在图像生成任务中，生成模型可以学习图像的分布，然后生成新的图像。生成的图像可以与训练数据中的图像具有相似的特征和风格。 常见类型： 1️⃣ 朴素贝叶斯模型， 是一种简单的生成模型，它基于贝叶斯定理和特征之间的独立性假设。朴素贝叶斯模型通过估计每个类别的先验概率和每个特征在每个类别下的条件概率来进行分类。在文本分类等任务中表现出了很好的性能。\n2️⃣ 隐马尔可夫模型（HMM） ，是一种用于序列数据建模的生成模型。它由一个隐藏状态序列和一个观察序列组成，隐藏状态之间存在转移概率，观察值由隐藏状态生成。在语音识别、自然语言处理等领域有广泛的应用。\n3️⃣ 变分自编码器（VAE） ，是一种基于深度学习的生成模型。它由一个编码器和一个解码器组成，编码器将输入数据映射到一个低维的潜在空间，解码器则从潜在空间中生成新的数据样本。VAE 通过最大化数据的似然函数来学习潜在空间的分布，同时通过约束潜在空间的分布使其接近一个标准的高斯分布，从而实现了生成新数据的目的。\n4️⃣ 生成对抗网络（GAN） ，生成对抗网络是一种由生成器和判别器组成的深度学习模型。生成器的目标是生成与真实数据相似的假数据，判别器的目标是区分真实数据和生成器生成的假数据。\n2.3、其他分类 2.3.1、线性\\非线性 线性模型； 线性模型是一种最简单也最重要的统计与机器学习模型。\n在线性模型中，输出是输入特征的线性组合。换句话说，假设特征和输出之间的关系是线性的，即满足一次方程。\n线性模型的一个主要优点是简单易理解、计算效率高，例如线性回归和逻辑回归。\n然而，现实生活中很多问题，特征和输出之间的关系复杂，非线性的。对于这类问题，线性模型的表达能力就显得不够。\n非线性模型； 非线性模型则假设输入与输出之间是非线性关系。\n非线性关系的形式有很多，可能是二次、三次甚至更高次的多项式形式，也可能是指数、对数形式，等等。\n非线性模型的一个主要优点是可以拟合更复杂的关系，例如决策树、神经网络等。\n然而，非线性模型的主要挑战在于可能会过拟合数据（即模型对训练数据学习的过于复杂，不能很好地泛化到新的数据上）、和计算上的复杂性。\n2.3.2、概率\\非概率 概率模型； 概率模型是一种基于概率理论的统计模型，它描述了随机变量之间的概率关系。\n在概率模型中，我们不仅预测某一结果，而且还给出了预测的不确定性（以概率的形式）。\n例如，朴素贝叶斯，高斯混合模型，隐马尔可夫模型，逻辑回归等都是概率模型。\n概率模型的一个主要好处是给出了预测的不确定性，这在许多应用中是非常有用的，如天气预测、医疗诊断等。\n但是概率模型一般假定数据满足某种分布，这种假设在一些情况下可能过于严格，限制了模型的适应性。\n非概率模型； 非概率模型不依赖于先验的可能性模型，而通常依赖于万丽最优化级星拉。\n非概率模型给出明确的预测，不提供预测的不确定性（即预测的概率）。\n例如，支持向量机，决策树，深度学习神经网络等都属于非概率模型。\n非概率模型的优点是无需对数据分布做过多假设，这使得它们更具有适应性，能够处理各种复杂的数据情况。\n然而，非概率模型并不提供预测的不确定性，这在某些情况下可能是一个缺点。\n2.3.3、参数\\非参数 参数模型； 参数模型是一种假设输入和输出之间的关系可以由一组参数完全确定，并且这组参数的数量是固定的。\n参数模型一般都有严格的假设，例如假设数据是正态分布的，或者输入和输出之间的关系是线性的等。\n常见的参数模型包括线性回归、逻辑回归、线性判别分析等。\n参数模型的优点是理论清晰，计算相对简单。\n然而，缺点是对数据的假设可能过于严格，如果实际数据的分布或者结构与模型的假设不符，那么参数模型的表现可能会很差。\n非参数模型； 非参数模型非常灵活，它不假设数据必须符合某一特定的分布，或者输入和输出间的关系必须是某一特定的形式。\n非参数模型的参数数量通常会随着数据量的增加而增加。\n常见的非参数模型包括决策树、随机森林、支持向量机等。\n非参数模型的优点是非常灵活，可以处理各种复杂的数据情况。\n然而，非参数模型的缺点是计算上可能会比较复杂，而且由于模型过于灵活，如果数据量不足，可能会导致过度拟合。\n2.3.4、基于实例\\模型 基于实例的学习； 系统先完全记住学习示例（example），然后通过某种相似度度量方式将其泛化到新的实例。\n基于实例的算法直接记住并使用训练实例进行预测，它们是一种惰性学习算法，因为它们仅在预测时进行计算。\n一个典型例子就是最近邻算法。\n基于实例的学习的优点是可以适应复杂的问题，因为它们不需要进行任何明确的模拟。\n然而，存储和比较所有训练实例通常会造成大量的计算开销。\n基于模型的学习； 在训练过程中会构建一个预测模型，然后使用该模型进行预测。这就是基于模型的学习。\n这种模型可以是线性的（例如线性回归），也可以是非线性的（例如神经网络），或者是更复杂的结构（例如决策树或随机森林）。\n构建模型的敏感过程（例如参数选择，模型选择）通常是自动进行的，并且侧重于提高预测的准确性。\n基于模型的学习的一个主要优点是它们通常可以更有效地处理大量数据。\n然而，选择正确的模型并调整模型参数通常需要专门知识，并可能需要大量时间来得到满意的结果。\n2.3.5、离线\\在线学习 离线学习； 离线学习，又称为批量学习，是最常见的学习方式。\n在离线学习中，我们先从一个固定的训练集中学习模型，然后将该模型应用于新的未知数据。\n由于训练过程是从一个固定的数据集中进行的，因此可以对数据进行多次处理，也就是说可以重复训练。\n此外，训练过程通常需要大量的计算资源，因此通常在专用的机器上进行，并可能需要花费很长时间。\n在线学习； 在线学习是一种连续的学习方式，可以适应新数据的出现。\n在在线学习中，模型以连续的方式接收数据并不断调整，因此能够实时适应新的信息。\n这种学习方式非常适合那些需要不断适应新数据或数据量过大无法一次性处理的场景。\n然而，由于在线学习需要实时进行，因此其计算资源的需求通常比离线学习要更高。","3统计机器学习#\u003cfont face=Georgia\u003e3、统计机器学习\u003c/font\u003e":"3.1、定义 从给定的数据集合出发，假设数据是独立同分布 产生的：并且假设要学习的 模型属于某个函数的集合 ，称为 假设空间 ；应用某个评价准则，从假设空间中 选取一个最优模型，使它对已知的训练数据及未知的测试数据在给定的评价准则下有最优的预测；最优模型的选取由算法实现。\n统计学习方法包括：模型的假设空间、模型选择的准则 及 模型学习的算法 。 统称为统计学习方法的三要素，简称为 模型、策略 和 算法。 3.2、三要素 1️⃣ 模型： 在监督学习过程中，模型就是所要学习的 条件概率分布 或 决策函数。模型的 假设空间 包含所有可能的 条件概率分布 或 决策函数。例如，假设决策函数是输入变量的线性函数，那么模型的假设空间就是所有这些线性函数构成的函数集合。假设空间一般有无穷多个。\n决策函数： 假设假设空间用 $\\mathcal{F}$ 表示。假设空间可以定义为 决策函数的集合：\n$$\\mathcal{F}={\\begin{array}{c}f\\mid Y=f(X)\\end{array}}$$\n其中：\n$X$ 和 $Y$ 是定义在输入空间 $\\mathcal{X}$ 和输出空间 $\\mathcal{Y}$ 上的变量。 这时 $\\mathcal{F}$ 通常是由一个参数向量决定的函数族： ${\\mathcal F}={f|Y=f_{\\theta}(X),\\theta\\in\\mathbf{R}^{n}}$。 参数向量 $\\theta$ 取值于 $n$ 维欧式空间 $\\mathbf{R}^{n}$ ，称为参数空间。 条件概率分布：假设空间 $\\mathcal{F}$ 也可以定义为 条件概率的集合：\n$$\\mathcal{F}={P\\mid P(Y|X)}$$\n其中：\n$X$ 和 $Y$ 是定义在输入空间 $\\mathcal{X}$ 和输出空间 $\\mathcal{Y}$ 上的随机变量。 这时 $\\mathcal{F}$ 通常是由一个参数向量决定的条件概率分布族： ${\\mathcal F}={P\\mid P_{\\theta}(Y|X),\\theta\\in\\mathbf{R}^{n}}$。 参数向量 $\\theta$ 取值于 $n$ 维欧式空间 $\\mathbf{R}^{n}$ ，称为参数空间。 2️⃣ 策略： 策略就是从模型的假设空间中，选择损失函数值最小的模型。 使用损失函数(loss function) 或 代价函数(cost function) 来衡量模型预测的错误程度。 损失函数值越小，模型越好。\n1. 损失函数：(loss function)： 损失函数是 $f(X)$ 和 $Y$ 的非负实值函数，记作 $L(Y,f(X))$。 常见的损失函数如下： (1). 0-1 损失函数 （0-1 loss function）： $$\\small L(Y,f(X))=\\begin{cases}1,\u0026Y\\neq f(X)\\\\ 0,\u0026Y=f(X)\\end{cases} \\tag{1}$$\n(2). 平方损失函数 （quadratic loss function）： $$\\small L(Y,f(X))=(Y-f(X))^{2} \\tag{2}$$\n(3). 绝对损失函数 （absolute loss function）： $$\\small L(Y,f(X))=|Y-f(X)| \\tag{3}$$\n(4). 对数损失函数 （logarithmic loss function）： $$L(Y,P(Y|X))=-\\log P(Y|X) \\tag{4}$$\n其中：$P(Y|X)$ 是条件概率分布，$-\\log P(Y|X)$ 是对数似然函数。 2. 风险函数：(risk function)： 由于模型的输入、输出 $（X, Y）$ 是随机变量，遵循联合分布 $P(X, Y)$，所以损失函数的期望 $\\small R_{\\exp}$ 如下；这是理论上模型 $f(X)$ 关于联合分布 $P(X, Y)$ 的平均损失，称为 风险函数 (risk function) 或 期望损失 (expected loss)。 $$\\small R_{\\exp}(f)=E_{P}[L(Y,f(X))]=\\int_{x\\times y}L(y,f(x))P(x,y)\\mathrm{d}x\\mathrm{d}y$$ 由于联合分布 $P(X,Y)$ 未知，所以无法直接计算期望风险 $\\small R_{\\exp}(f)$。 学习的目标（策略）就是选择期望风险最小的模型。 3. 经验风险：(empirical risk)： 给定一个训练数据集 $T={(x_{1},y_{1}),(x_{2},y_{2}),\\cdots,(x_{N},y_{N})}$，模型 $f(X)$ 在训练数据集上的平均损失称为 经验风险\\损失，记作$\\small R_{emp}(f)$： $$R_{\\mathrm{emp}}(f)=\\frac{1}{N}\\sum_{i=l}^{N}L(y_{i},f(x_{i}))$$\n根据大数定律，当样本数 $N$ 足够大时，经验风险 $\\small R_{emp}(f)$ 收敛于期望风险 $\\small R_{\\exp}(f)$。所以能用经验风险估计期望风险。\n由于现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险常常并不理想，要对经验风险进行一定的矫正。这就关系到监督学习的两个基本策略:经验风险最小化 和 结构风险最小化。\n❓ 大数定理 是概率论中一系列定理的统称，最常见的表述为： 随着样本数量的增加，样本均值会趋近于总体均值。更严格地说，如果 $X_1, X_2, … , X_n$ 是一系列独立同分布的随机变量，且它们的期望为 $\\mu$，方差为 $\\sigma^2$，那么当 $n$ 趋向于无穷大时，样本均值 ${\\overline{X}}={\\frac{1}{n}}\\sum_{i=1}^{n}X_{i}$ 依概率收敛于 $\\mu$，即对于任意正数 $\\epsilon$ ，有： $$\\lim_{n\\to\\infty}P\\left(\\left|\\overline{X}-\\mu\\right|\u003c\\epsilon\\right)=1$$ 简单来说，大数定理表明在大量重复试验中，事件发生的频率会趋近于其概率。它是概率论和统计学中非常重要的基础性定理，为用样本估计总体提供了理论依据。 4. 经验风险最小化 (empirical risk minimization，ERM) 在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数就可以确定。 经验风险最小化 (empirical risk minimization，ERM) 的策略认为，经验风险最小的模型是最优的模型。根据这一策略，按照经验风险最小化求最优模型就是 求解最优化问题： $$\\min_{f\\in\\mathcal{F}}\\frac{1}{N}\\sum_{i=1}^NL(y_i,f(x_i))$$ 其中，$\\mathcal{F}$ 是假设空间。\n当样本容量足够大时，经验风险最小化能保证有很好的学习效果，在现实中被广泛采用。\n比如，极大似然估计 (maximumlikelihood estimation) 就是经验风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。\n当样本容量很小时，经验风险最小化学习的效果就未必很好，会产生“过拟合”(over-ftting) 现象。 5. 结构风险最小化 (structural risk minimization，SRM) 结构风险最小化 (structural risk minimization，SRM) 是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化 (regularization)。结构风险在经验风险上加上表示模型复杂度的正则化项 (regularizer) 或罚项 (penaltyterm)。 在假设空间、损失函数以及训练数据集确定的情况下， 结构风险的定义 是: $$R_{\\mathrm{srm}}(f)=\\frac1N\\sum_{i=1}^NL(y_i,f(x_i))+\\lambda J(f)$$ 其中 $J(f)$ 为模型的复杂度，是定义在假设空间 $\\mathcal{F}$ 下上的泛函。 模型 $f$ 越复杂，复杂度 $J(f)$ 就越大;反之，模型 $f$ 越简单，复杂度 $J(f)$ 就越小。 也就是说，复杂度表示了对复杂模型的惩罚。$\\lambda≥0$ 是系数,用以权衡经验风险和模型复杂度。 结构风险小需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。 比如，贝叶斯估计中的最大后验概率估计 (maximum posterior probability esti-mation，MAP) 就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。\n结构风险最小化的策略认为结构风险最小的模型是最优的模型。所以求最优模型，就是求解最优化问题: $$\\min_{f\\in\\mathcal{F}}\\frac{1}{N}\\sum_{i=1}^{N}L(y_i,f(x_i))+\\lambda J(f)$$ 这样，监督学习问题就变成了 经验风险 或 结构风险函数 的最优化问题。这时 经验或结构风险函数 是最优化的目标函数。 3️⃣ 算法： 算法是指学习模型的具体计算方法。统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。\n这时，统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的算法。如果最优化问题有显式的解析解，这个最优化问题就比较简单。但通常解析解不存在，这就需要用数值计算的方法求解。如何保证找到全局最优解，并使求解的过程非常高效，就成为一个重要问题。统计学习可以利用已有的最优化算法，有时也需要开发独自的最优化算法。\n统计学习方法之间的不同，主要来自其模型、策略、算法的不同。确定了模型、策略、算法，统计学习的方法也就确定了。这就是将其称为统计学习方法三要素的原因。\n3.3. 步骤： 得到一个有限的训练数据集合； 确定包含所有可能的模型的假设空间，即学习 模型的集合 （条件概率分布 或 决策函数）； 确定模型选择的准则，即学习的 策略（损失函数）； 实现求解最优模型的算法，即学习的算法； 通过学习方法选择最优模型； 利用学习的最优模型对新数据进行预测或分析； 3.4. 统计机器学习 VS 统计学 统计学 的最新进展均致力于为回归和分类提供更强大的自动预测建模技术。这些方法都属于统计机器学习。 不同于经典的统计方法，统计机器学习 是数据驱动的，并不试图在数据上强加线性结构或其他的整体结构。\n不需要过多关注数据分布、假设检验，数据泛化能力更有用。 最近邻算法就是一种非常简单的方法，它根据与一个记录相似的记录的分类情况，对该记录进行分类。 最为成功的技术，是结合决策树的集成学习。集成学习的基本理念是，运用多个模型而非单一模型去生成预测。 决策树对于学习预测变量和结果变量之间关系的规则，是一种灵活且自动化的技术。 事实证明，集成学习与决策树相结合，可以得到性能优良的、可用的预测建模技术。 3.5. 统计机器学习 VS 机器学习 二者之间并不存在一条明确的分界线。 机器学习更关注 如何开发可扩展到大规模数据上的高效算法，以便于优化预测模型。 统计学更关注的是 概率理论和模型的底层结构。 Bagging算法 和 随机森林 方法完全是从统计学领域发展出来的。 Boosting方法 从这两个学科中发展起来的，只是在机器学习一方得到了更多的关注。 如果不看历史的话，Boosting 的发展确保了该技术同时适用于统计学和机器学习这两个领域。 ","4模型评估选择#\u003cfont face=Georgia\u003e4、模型评估选择\u003c/font\u003e":"4.1、模型泛化 模型泛化 指的是模型对新的、未曾见过的数据的适应能力和预测能力。 一个具有良好泛化能力的模型，不仅在训练数据上表现出色，在面对新的、来自相同分布的测试数据或实际应用中的数据时，也能给出准确和可靠的预测结果。\n如果模型 过度拟合 训练数据，会记住训练数据中的噪声和特定细节，导致泛化能力差，在新数据上表现不佳；而如果模型 欠拟合 训练数据，则无法充分学习到数据中的模式和规律，同样泛化能力不佳。\n评估模型泛化能力的常见方式是在独立的测试集上对模型进行测试，并观察其性能指标。\n4.2、过拟合 过拟合$（Overfitting）$ 指模型在训练数据上表现得非常好，但在新的、未见过的数据上表现很差。 通常是因为 模型过于复杂，学习到了训练数据中的噪声和一些特定的、不具有普遍性的特征，而不是真正的数据模式和规律。 过拟合的 表现包括 ：在训练集上准确率很高，但在测试集上准确率显著下降；模型对训练数据的微小变化非常敏感。 导致过拟合的 原因可能有 ：数据量过少、模型过于复杂（例如层数过多、参数过多）、训练时间过长等。\n处理过拟合的方法主要有以下几种： 增加数据量：收集更多的相关数据，以丰富模型的学习内容，使其能够更好地捕捉数据的普遍规律，而不是局限于训练数据中的噪声和特殊情况。 数据增强：通过对现有数据进行随机变换，如翻转、旋转、缩放、添加噪声等，增加数据的多样性。 简化模型：减少模型的复杂度，例如减少网络层数、神经元数量，或者使用更简单的模型结构。 正则化： L1 和 L2 正则化：在损失函数中添加对模型参数的惩罚项，限制模型参数的大小，防止过度拟合。 Dropout：在训练过程中随机地将神经元的输出设置为 0，强迫模型学习更鲁棒的特征表示。 早停法\\Early Stopping：在训练过程中，持续监测模型在验证集上的性能，当性能不再提升时提前停止训练。 集成学习：例如使用随机森林等集成学习方法，通过组合多个模型来降低过拟合的风险。 特征选择：去除一些不重要或冗余的特征，降低模型学习的难度。 交叉验证：使用多种交叉验证方法，如 K 折交叉验证，更准确地评估模型性能，并选择合适的超参数。 4.3、欠拟合 欠拟合$（Underfitting）$ 指模型在训练数据和测试数据上的表现都不好。这意味着模型没有充分学习到数据中的模式和规律，过于简单或者训练不充分。 欠拟合的 表现是 模型在训练集和测试集上的误差都较大，且两者的差距较小。 导致欠拟合的 原因可能是 ：模型的能力不足、特征选择不当、训练次数太少等。\n处理欠拟合的方法通常包括以下几种： 增加模型复杂度： 对于神经网络，可以增加层数或神经元数量。 对于传统机器学习算法，例如决策树，可以增加树的深度。 增加特征数量：尝试引入更多相关的特征，以提供更多信息给模型进行学习。 选择更强大的模型：例如从线性模型切换到非线性模型，如使用支持向量机、决策树或神经网络等。 调整超参数：通过试验不同的超参数组合，找到最适合当前数据和任务的设置。 延长训练时间：确保模型有足够的时间来学习数据中的模式。 数据预处理：对数据进行更有效的清洗、归一化、标准化等处理，以改善数据质量和模型的学习效果。 组合多个模型：通过集成多个弱学习器来构建一个更强的学习器。 尝试新的算法：如果当前使用的算法效果不佳，可以尝试其他适合该任务和数据特点的算法。 4.4、评估指标 （1）分类评估指标 1、混淆矩阵： 真实值 总数 $\\pmb{\\it{p}} \\,(positive)$ $\\pmb{\\it{n}}\\,(negative)$ 预测值 $\\pmb{\\it{p'}}\\,(positive)$ TP FP P' $\\pmb{\\it{n'}}\\,(negative)$ FN TN N' 总数 P N 阳性 $(P, positive)$ 阴性 $(N, Negative)$ 真阳性 $(TP, true positive)$ 正确的肯定。又称：命中 $(hit)$ 真阴性 $(TN, true negative)$ 正确的否定。又称：正确拒绝 $(correct rejection)$ 伪阳性 $(FP, false positive)$ 错误的肯定，又称：假警报 $(false alarm)$，第一型错误 伪阴性 $(FN, false negative)$ 错误的否定，又称：未命中 $(miss)$，第二型错误 优点： 提供了关于分类模型在各个类别上的详细分类情况，包括正确分类和错误分类的数量。 直观易懂，能够清晰地展示模型的分类效果。 缺点： 对于多分类问题，混淆矩阵可能会变得非常复杂和庞大，不太容易直观地理解。 单独的混淆矩阵本身并不能直接给出一个单一的综合评估指标。 适用情况： 当需要详细了解模型在每个类别上的分类表现时，混淆矩阵非常有用。 在比较不同分类模型或调整模型参数时，可以通过分析混淆矩阵来洞察模型的行为和改进方向。对于不平衡数据集（某些类别样本数量远多于或少于其他类别），混淆矩阵可以帮助发现模型对少数类别的分类效果。 2、准确率$（Accuracy）$： 准确率 $（Accuracy）$：正确预测的样本数占总样本数的比例。公式为： $$Accuracy = \\frac{(TP + TN)}{(TP + TN + FP + FN)}$$\n优点：\n直观易懂：是一个非常直观和易于理解的指标，能够简单地反映模型整体分类正确的比例。 综合性：综合考虑了所有类别的分类情况。 缺点： 类别不平衡问题：在数据存在类别不平衡（某些类别样本数量远多于或远少于其他类别）时，准确率可能会产生误导。例如，在一个二分类问题中，99%的样本属于类别 A，1%属于类别 B，如果模型总是预测为类别 A，准确率也能达到 99%，但实际上对类别 B 的分类效果很差。 不能区分不同类别的错误情况：无法提供关于每个类别分类错误的具体信息，可能掩盖了某些重要类别上的糟糕表现。 缺乏细节：不能反映模型在不同类别上的性能差异，对于需要深入了解模型在各个类别上表现的情况，准确率提供的信息有限。 3、精确率$（Precision）$： 精确率$（Precision）$： 在被预测为正例的样本中，真正的正例所占的比例。公式为： $$Precision = \\frac{TP}{TP + FP}$$\n优点：\n聚焦正例的准确性：精确率重点关注被模型预测为正例的样本中，真正为正例的比例。这在一些对正例预测的准确性要求较高的场景中非常有用，例如在疾病诊断中，确保被诊断为患病的人确实患病是至关重要的。 适用于类别不平衡数据：在正例样本相对较少的不平衡数据集中，精确率能够更有针对性地评估模型对正例的预测能力。 缺点：\n忽略了负例的情况：精确率只考虑了被预测为正例的样本，而完全忽略了被预测为负例的样本，可能会导致对模型整体性能的评估不全面。 孤立的评估指标：单独依靠精确率不能完全反映模型的综合性能，往往需要结合其他指标如召回率、F1 值等来进行更全面的评估。 受阈值影响：精确率的值会受到分类阈值的选择影响，不同的阈值可能会导致精确率的变化，这使得在比较不同模型或方法时需要谨慎处理阈值的设置。 4、召回率$（Recall）$、命中率 $(hit rate)$、敏感度 $(sensitivity)$： 召回率$（Recall）$： 实际的正例样本中，被正确预测为正例的比例。公式为： $$Recall = \\frac{TP}{TP + FN}$$\n优点：\n强调对正例的全面覆盖：召回率关注的是在所有实际为正例的样本中，被正确预测为正例的比例。这对于一些重视不能遗漏正例的任务非常重要，比如疾病检测，确保尽可能多地发现真正的患者。 适用于不平衡数据：在数据集中正例相对较少的情况下，召回率能够反映出模型在捕捉少数类（正例）方面的能力。 缺点：\n可能忽视误报：高召回率可能是以增加误报（将负例错误地预测为正例）为代价的，而召回率本身并不能直接反映这一情况。 单独使用不够全面：仅依靠召回率来评估模型的性能可能不够全面，通常需要结合准确率、F1 值等其他指标进行综合评估。 对负例的判断不敏感：召回率主要关注正例的预测情况，对于负例的准确预测情况反映较少。 5、F1 分数$（F1-score）$： F1 分数$（F1-score）$： 是精确率和召回率的调和平均数，综合考虑了两者的平衡。一般式为： $$F_\\beta=(1+\\beta^2)\\cdot\\frac{\\text{precision}\\cdot\\text{recall}}{(\\beta^2\\cdot\\text{precision})+\\text{recall}}$$ $\\beta$ 是使用者自行定义的参数，由一般式可见 $F-score$ 能同时考虑 $precision$ 和 $recall$ 这两种数值。分子为 $precision$ 和 $recall$ 相乘，根据这个式子，只要 $precision$ 或 $recall$ 趋近于 0，$F-score$ 就会趋近于0，代表着这个算法的精确度非常低。一个好的算法，最好能够平衡 $recall$ 和 $precision$ ，且尽量让两种指标都很高。所以有一套判断方式可以同时考虑 $recall$ 和 $precision$ 。当 $\\beta\\to0$ 时，$F-score$ 退化为 $precision$ ；当 $\\beta\\rightarrow\\infty$ 时，$F-score$ 退化为 $recall$。\n$Precision$ 和 $Recall$ 权重一样时：一般上来说，提到 $F-score$ 且没有特别的定义时，是指 $\\beta=1$ 时的 $F-score$，亦有写作 $F1-score$。代表使用者同样的注重 $precision$ 和 $recall$ 的这两个指标。其分数可以说是 $precision$ 和 $recall$ 的调和平均，式子如下：\n$$F_1=\\frac{2}{\\text{recall}^{-1}+\\text{precision}^{-1}}=2\\frac{\\text{precision}\\cdot\\text{recall}}{\\text{precision}+\\text{recall}}=\\frac{2TP}{2TP+FP+FN}$$\n$F-score$ 最理想的数值是趋近于1，做法是让 $precision$ 和 $recall$ 都有很高的值。若两者皆为1，使得 $2*\\frac{1}{2}=1$，则 $F-score = 1$ （100%），代表该算法有着最佳的精确度。\n优点： 综合考虑了准确率和召回率：F1 分数是准确率和召回率的调和平均数，能够平衡模型在这两个方面的表现，对于需要同时关注查准和查全的任务非常有用。 适用于不平衡数据：在正例和负例数量差异较大的情况下，F1 分数能够更全面地评估模型性能，避免只侧重准确率或召回率中的某一个。 单一数值便于比较：F1 分数是一个单一的数值，便于在不同模型或不同参数设置之间进行比较和选择。 缺点： 对极端值敏感：当准确率或召回率中有一个非常接近 0 时，F1 分数会受到较大影响。 可能掩盖某些问题：虽然综合了准确率和召回率，但不能直接反映出模型在这两个指标上的具体差异和潜在的问题。 不完全反映实际需求：在某些特定场景中，可能更关注准确率或者召回率中的某一个，而 F1 分数不能完全突出这种特定的需求。 （2）多标签分类评估 4.5、评估方法 （1）留出法 留出法 $（Hold-out Method）$ 是一种常见的机器学习模型评估方法。\n基本思想：\n将数据集划分为两个互斥的集合，分别是 训练集 和 测试集。通常，大部分数据被分配到训练集，用于模型的学习和训练；小部分数据被分配到测试集，用于评估训练好的模型的性能。\n划分要具有随机性，以避免数据的偏差。 训练集和测试集的样本分布应尽量与原始数据集的分布保持一致。注意通过关键分类指标进行分层拆分。 通常，将大约 70%-80% 的数据作为训练集，20%-30% 的数据作为测试集，但具体比例可以根据数据规模和实际需求进行调整。 如果需要查看模型在新数据上的表现情况，或是模型需要调整参数，也可以在 验证集 上测试。\n将数据集划分为三个互斥的集合，分别是 训练集，测试集 和 验证集， 比例可以为 60%，20%，20% 优点：\n简单、直接； 计算开销小； 缺点：\n评估结果可能不稳定； 受划分数据随机性影响较大 （2）交叉验证 交叉验证（Cross Validation）是一种用于评估机器学习模型性能和选择合适模型超参数的技术。如，常见的 K 折交叉验证。\nK 折交叉验证原理：\n将数据集随机平均分成 K 份。每次选择其中 1 份作为测试集，其余 K - 1 份作为训练集，重复 K 次，这样每个子集都有机会作为测试集，最终得到 K 个模型的评估结果。综合这 K 个结果来估计模型的泛化能力。\n例如，对于 5 折交叉验证，数据被分为 5 份。第一次，第 1 份作为测试集，其余 4 份作为训练集；第二次，第 2 份作为测试集，其余 4 份作为训练集，以此类推，共进行 5 次训练和测试。\n优点：\n更充分地利用了数据，减少了由于数据划分随机性导致的偏差。 可以用于评估模型在不同数据子集上的稳定性和泛化能力。 缺点：\n计算成本相对较高，特别是当 K 值较大或数据集较大时。 对于时间开销较大的模型，可能会耗费较多的时间。 交叉验证在模型选择、超参数调优、评估模型稳定性等方面都有广泛的应用。 （3）留一法 留一法（Leave-One-Out，LOO）是一种特殊的交叉验证方法。在留一法中，每次从样本集中取出一个样本作为测试集，其余的样本作为训练集，重复这个过程直到所有的样本都被用作一次测试样本。\n假设样本集有 $n$ 个样本，那么就会进行 $n$ 次训练和测试。在每次迭代中，将其中一个样本作为测试样本，其余 $n-1$ 个样本作为训练样本进行模型训练，然后用训练好的模型对那个被取出的样本进行预测，并记录预测结果。最后，综合这 $n$ 次预测结果来评估模型的性能。\n优点：\n充分利用数据 由于每次只留下一个样本进行测试，几乎使用了所有的样本进行训练，因此对于小样本数据集来说，可以最大限度地利用数据信息，使得评估结果更加准确。\n无偏估计 留一法的评估结果通常是无偏的，因为每个样本都被单独用作测试集，避免了随机划分训练集和测试集可能带来的偏差。\n缺点：\n计算成本高 由于需要进行 次训练和测试，当样本数量较大时，计算量会非常大，导致训练和评估过程非常耗时。\n不一定反映真实性能 在某些情况下，留一法可能会过于乐观地估计模型的性能，因为每次训练集和测试集之间的差异非常小，模型可能会过度拟合到特定的测试样本。而且，由于每次只改变一个样本进行测试，可能无法很好地反映模型在不同数据分布下的泛化能力。","参考网址#\u003cfont face=Georgia\u003e参考网址：\u003c/font\u003e":" Training | Microsoft Learn — 基本 AI 概念 《Python深度学习》- 第2版 - 弗朗索瓦·肖莱 《机器学习实战：基于 Scikit-Learn、Keras 和 TensorFlow》 第2版 《统计学习方法》 第2版 - 李航 "},"title":"1.1. 概述"},"/documentation/ai/end_to_end/tool/":{"data":{"":"\nPandas一个快速、强大、灵活且易于使用的开源数据分析和操作工具。 数据分析 SklearnPython 中的机器学习；简单有效的预测数据分析工具。 机器学习 Matplotlib用 Python 创建静态、动画和交互式可视化。 "},"title":"1.2. 工具"},"/documentation/bigdata/":{"data":{"":" 基础知识简单易用，功能强大丰富。 核心框架简单易用，功能强大丰富。 数据仓库B 站，数仓项目学习（尚硅谷，等）； 数据治理简单易用，功能强大丰富。 "},"title":"大数据"},"/documentation/bigdata/base/":{"data":{"":"\nLinux\\ShellLinux 是一种自由和开放源码的类 UNIX 操作系统。 大数据\\云计算基础 Java由 Sun 公司于 1995 年 5 月推出的高级程序设计语言。 大数据基础 Maven一款 Java 项目的构建工具。Maven 使用项目对象模型 (POM) 来管理项目的编译、测试和文档。 Scala一种可随您扩展的编程语言：从小型脚本到大型多平台应用程序。 大数据基础 MySQL一个流行的关系型数据库管理系统。 "},"title":"1. 基础知识"},"/documentation/bigdata/data_warehouse/":{"data":{"":" 范式数据表结构符合某种设计标准的级别。 "},"title":"3. 数据仓库"},"/documentation/bigdata/data_warehouse/paradigm/":{"data":{"":"","1-什么是范式#1. 什么是范式？":" 王珊的《数据库系统概论》中的定义，范式是“符合某一种级别的关系模式的集合，表示一个关系内部各属性之间的联系的合理化程度”。\n简单说就是 数据表结构符合某种设计标准的级别。 ","2-范式特点#2. 范式特点":" 范式级别越高，表设计越标准、规范化；（数据冗余更少；数据一致性更强；依赖关系更合理） 高级别范式必定符合低级别范式要求(如符合2NF必定符合1NF)； 常见范式有1NF、2NF、3NF、BCNF、4NF、5NF； 零范式：数据中不存在重复数据； 一范式：在零范式的基础上，加上关系中的 每个属性（字段）都不可再分（原子性）； ","3-常见范式#3. 常见范式":"3.1. 零范式 零范式：数据中不存在重复数据。 学生成绩记录 1001,张三,CS101,90 1002,李四,MATH202,85 1003,王五,PHYS101,92 1004,赵六,CHEM304,88 3.2. 一范式 一范式：在零范式的基础上，加上关系中的每个属性（字段）都不可再分（原子性）\n在零范式的基础上 加上关系中的每个属性（字段）都不可再分（原子性） 这个条件后便形成了符合一范式的表。\n1NF是所有关系型数据库的最基本要求。 学号 姓名 课程编号 课程名称 成绩 教师 1001 张三 CS101 数据库 90 王老师 1001 张三 MATH202 高等数学 85 李老师 1002 李四 CS101 数据库 88 王老师 1002 李四 CS101 python 98 张老师 一范式（1NP）存在的问题：\n3.3. "},"title":"3.1. 范式"},"/documentation/cc/":{"data":{"":" 基础知识简单易用，功能强大丰富。 云原生简单易用，功能强大丰富。 "},"title":"云计算"},"/guide/":{"data":{"":"","1数学知识#1、数学知识":" 微积分是研究变化\\微分与累积\\积分的数学分支，用于解决运动、曲线、面积等动态问题。 AI 基础 线性代数是研究向量、矩阵和线性变换的数学分支，核心用来解方程、处理空间变换和数据分析。 AI 基础 概率论是研究随机现象规律性的数学分支，用概率量化不确定性。 AI 基础 数理统计是用数学工具（尤其是概率论）从数据中总结规律、预测未知的学科，核心是抽样、估计和假设检验。 AI 基础 ","2编程语言#2、编程语言":" Linux\\ShellLinux 是一种自由和开放源码的类 UNIX 操作系统。 大数据\\云计算基础 Python一种广泛使用的解释型、高级和通用的编程语言。 AI 基础 Java由 Sun 公司于 1995 年 5 月推出的高级程序设计语言。 大数据基础 Maven一款 Java 项目的构建工具。Maven 使用项目对象模型 (POM) 来管理项目的编译、测试和文档。 Scala一种可随您扩展的编程语言：从小型脚本到大型多平台应用程序。 大数据基础 Go一种快速、静态类型的编译语言，感觉就像是一种动态类型的解释语言。 云原生基础 markdownMarkdown是一种轻量级标记语言，排版语法简洁，让人们更多地关注内容本身而非排版。 编写文档 ","3人工智能#3、人工智能":"3.1、科学计算\\机器学习 NumpyPython 科学计算的基本包；强大的 N 维数组；数值计算工具。 数据分析 Pandas一个快速、强大、灵活且易于使用的开源数据分析和操作工具。 数据分析 SklearnPython 中的机器学习；简单有效的预测数据分析工具。 机器学习 Sklearn 源码Sklearn 源码\n机器学习 StatsmodelsPython 统计建模库；用于进行统计测试和统计数据探索。 统计模型 3.2、深度学习 Keras一个用 Python 编写的开源神经网络库。 TensorFlowGoogle Brain 团队开发的一个机器学习和深度学习的开源库。 TensorFlow 源码Tensorflow 源码 FastAIfastai 是一个深度学习库，易于使用且快速高效。 PyTorch一个基于 Python 的开源机器学习库。 PyTorch 源码PyTorch 源码\n…… DeZero使用 Python 从头开始实现深度神经网络。 3.3、自动机器学习 3.4、模型解释 SHAP一种博弈论方法，用于解释任何机器学习模型的输出。 3.5、模型部署 Streamlit一个开源 Python 框架；快速构建和部署强大的数据应用程序。 FlaskFlask 是一个轻量级的 WSGI Web 应用程序框架。 3.6、模型管理 MLflow开源开发者平台，可自信地构建 AI 应用程序和模型。 实验跟踪 + 模型生命周期管理 KubeflowKubernetes 上 AI 平台工具的基础。 端到端机器学习流水线（生产级） W\u0026BWeights \u0026 Biases（W\u0026B）人工智能开发者平台，让您自信地构建人工智能代理、应用程序和模型。 实验跟踪 + 协作分析 + 可视化 3.7、训练调度 Airflow一个由社区创建的平台，用于以编程方式编写、安排和监控工作流程。 通用工作流编排 3.8、可视化 Matplotlib用 Python 创建静态、动画和交互式可视化。 Seaborn一个基于 matplotlib 的 Python 数据可视化库。 PlotlyPlotly 的 Python 图形库可制作交互式、出版质量的图形。 3.9、空间数据 GeoPandas旨在让使用 Python 处理地理空间数据变得更加容易。 Folium轻松地在交互式传单地图上可视化使用 Python 处理的数据。 ","4商业分析bi#4、商业分析：BI":" Datart新一代数据可视化开放平台。 观远 BI让业务用起来的现代化BI。 Quick BI一款全场景数据消费式的BI平台。 PowerBI由微软开发的商业分析工具集。 Tableau一款强大的数据可视化工具。 ","5数据库#5、数据库":" MySQL一个流行的关系型数据库管理系统。 PostgreSQL一个功能强大的开源对象关系数据库系统。 ","6大数据#6、大数据":"6.1、ETL 抽取\\转换\\加载 SeaTunnel下一代高性能 / 分布式、海量数据集成工具。\nWaterdrop（现更名为 SeaTunnel） 支持批流一体 Flink CDC一个基于流的数据集成工具，旨在为用户提供一套功能更加全面的编程接口（API）。 抽取 Flume一种分布式、可靠且可用的服务，用于高效收集、聚合和移动大量日志数据。 日志抽取\\加载 6.2、存储\\数据湖 IcebergApache Iceberg 是一种适用于大型分析表的高性能格式。 多引擎兼容 6.3、计算\\处理 Hadoop一个框架，允许使用简单的编程模型跨计算机集群分布式处理大型数据集。 存储\\批处理 HiveApache Hive 是一个分布式、容错数据仓库系统，可实现大规模分析。 批处理 Spark一个多语言引擎，用于在单节点机器或集群上执行数据工程、数据科学和机器学习。 批处理 Flink一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。 流处理 Kafka一个开源分布式事件流平台，实现高性能数据管道、流分析、数据集成和关键任务应用程序。 消息队列 + 流处理 Doris一个用于实时分析的现代数据仓库。它可以对大规模实时数据进行闪电般快速的分析。 OLAP StarRocks一款高性能分析型数据仓库，可进行多维、实时、高并发的数据分析。 OLAP 6.4、任务调度 Airflow一个由社区创建的平台，用于以编程方式编写、安排和监控工作流程。 通用工作流编排 DolphinScheduler一个多元化、可扩展的开源工作流协调平台，具有强大的DAG可视化界面。 6.5、开发\\IDE StreamPark一个用户友好的流媒体应用程序开发框架和一站式云原生实时计算平台。 Zeppelin基于 Web 的笔记本，支持使用 SQL、Scala、Python、R 等进行 数据驱动、交互式数据分析和协作文档。 6.6、治理：元数据\\血缘\\目录 DataHub 一个现代数据目录，旨在简化元数据管理、数据发现和数据治理。 数据目录\\血缘\\元数据 OpenMetadata一个统一的元数据平台，用于数据发现、数据可观测性和数据治理，由中央元数据存储库、深入的列级沿袭和无缝团队协作提供支持。 数据目录\\血缘\\质量\\元数据 6.7、治理：数据质量 Great Expectations批量和流式大数据质量解决方案。 Python/现代数据栈 Soda Core一个免费的开源 Python 库和 CLI 工具，使数据工程师能够测试数据质量。 低代码 6.8、治理：数据安全 Open Policy Agent一个开源的通用策略引擎，可在整个堆栈中实现统一的上下文感知策略实施。 云原生 Ranger一个框架，用于在整个 Hadoop 平台上启用、监控和管理全面的数据安全性。 HDFS/Hive/Kafka ","7云计算#7、云计算":"7.1、容器化 Docker一个开源的应用容器引擎，基于 Go 语言。 云原生 7.2、编排 Kubernetes开源容器编排引擎，用于自动部署、扩展和管理容器化应用程序 云原生 7.3、CI/CD GitGit 是一个免费的开源 分布式版本控制系统。 Github一个在线软件源代码托管服务平台，使用Git作为版本控制软件。 "},"title":"指南"},"/guide/bd_hive/":{"data":{"":"","一hive-概述#一、Hive 概述":"1.1、Hive 是什么？ Hive是由 Facebook 开源，基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL 查询功能。\n1.2、Hive 本质 Hive是一个Hadoop客户端，用于将 HQL（Hive SQL）转化成 MapReduce 程序。\n📝 Hive中每张表的数据存储在HDFS Hive分析数据底层的实现是 MapReduce（也可配置为Spark或者Tez） 执行程序运行在Yarn上 ","三hive-ddl数据定义#三、Hive DDL（数据定义）":"3.1、数据库 在 HiveSQL 中，你可以使用 CREATE DATABASE 语句来创建数据库。以下为你详细介绍其语法、参数说明以及提供一些具体案例。\n1️⃣ 创建 2️⃣ 查询 3️⃣ 修改 4️⃣ 删除 5️⃣ 切换 1CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name 2[COMMENT database_comment] 3[LOCATION hdfs_path] 4[WITH DBPROPERTIES (property_name=property_value, ...)]; (DATABASE|SCHEMA)：DATABASE 和 SCHEMA 是同义词，二者使用效果相同，用于指定创建的对象是数据库。 IF NOT EXISTS：这是一个可选参数。如果使用该参数，当要创建的数据库已经存在时，不会抛出错误，而是跳过创建操作；若不使用该参数，当数据库已存在时会报错。 database_name：此为必选参数，用于指定要创建的数据库的名称，名称需符合 Hive 的命名规则。 COMMENT database_comment：可选参数，用于为数据库添加注释信息，方便后续对数据库进行描述和管理。 LOCATION hdfs_path：可选参数，用于指定数据库在 HDFS（Hadoop Distributed File System）中的存储路径。若不指定，Hive 会使用默认路径。 WITH DBPROPERTIES (property_name=property_value, ...)：可选参数，用于为数据库设置一些自定义属性，属性以键值对的形式存在。 （1）、创建一个简单的数据库\n1CREATE DATABASE my_database; 此语句创建了一个名为 my_database 的数据库，使用的是 Hive 的默认存储路径，且没有添加注释和自定义属性。\n（2）、使用 IF NOT EXISTS 创建数据库\n1CREATE DATABASE IF NOT EXISTS my_database; 当 my_database 数据库不存在时，会创建该数据库；若已存在，则不会进行任何操作，也不会报错。\n（3）、创建带有注释的数据库\n1CREATE DATABASE my_database_with_comment 2COMMENT 'This is a test database for demonstration purposes'; 此语句创建了一个名为 my_database_with_comment 的数据库，并为其添加了注释信息，方便后续了解该数据库的用途。\n（4）、创建指定存储路径的数据库\n1CREATE DATABASE my_database_with_location 2LOCATION '/user/hive/warehouse/my_database_location'; 该语句创建了一个名为 my_database_with_location 的数据库，并将其存储在 HDFS 的 /user/hive/warehouse/my_database_location 路径下。\n（5）、创建带有自定义属性的数据库\n1CREATE DATABASE my_database_with_properties 2WITH DBPROPERTIES ('owner' = 'John', 'created_date' = '2024-01-01'); 此语句创建了一个名为 my_database_with_properties 的数据库，并为其设置了两个自定义属性：owner 的值为 John，created_date 的值为 2024-01-01。这些属性可以用于数据库的元数据管理。\nSHOW DATABASES 展示所有数据库\n1SHOW DATABASES [LIKE 'identifier_with_wildcards']; 列出 Hive 中所有的数据库；可以使用 LIKE 子句配合通配符进行过滤，%：匹配任意多个字符，_：匹配单个字符。 （1）、列出所有数据库：\n1SHOW DATABASES; （2）、列出名称以 “test” 开头的数据库：\n1SHOW DATABASES LIKE 'test%'; （3）、列出名称包含 “data” 的数据库：\n1SHOW DATABASES LIKE '%data%'; （4）、列出名称第二个字符是 “a” 的数据库：\n1SHOW DATABASES LIKE '_a%'; DESCRIBE DATABASE 查看数据库信息\nDESCRIBE DATABASE [EXTENDED] db_name; 显示指定数据库的元数据信息 不使用 EXTENDED 时显示基本信息 使用 EXTENDED 时显示更详细的扩展信息 📝 基本信息 (DESCRIBE DATABASE)：\n数据库名称 描述信息 位置 URI 所有者名称 所有者类型 权限信息 扩展信息 (DESCRIBE DATABASE EXTENDED)：\n包含基本所有信息 附加参数信息 创建时间等更多元数据 注意事项\n数据库名称区分大小写（取决于 Hive 配置） 需要有相应的权限才能查看数据库信息 DESCRIBE DATABASE 命令在Hive 0.14 及以上版本才完全支持 在旧版本 Hive 中，可能需要使用 DESCRIBE SCHEMA 替代 （1）、查看数据库的基本信息：\n1DESCRIBE DATABASE mydb; （2）、查看数据库的详细信息：\n1DESC DATABASE EXTENDED mydb; ","二hive-安装#二、Hive 安装":"","四hive-dml数据操作#四、Hive DML（数据操作）":""},"title":"Hive"},"/guide/markdown/":{"data":{"":"这篇文章提供了一些基础的 Markdown 语法样例，这些可以在 Hugo 的内容文件中使用。","参考#参考":" Markdown Syntax Hugo Markdown Note\nUseful information that users should know, even when skimming content. Tip\nHelpful advice for doing things better or more easily. Important\nKey information users need to know to achieve their goal. Warning\nUrgent info that needs immediate user attention to avoid problems. Caution\nAdvises about risks or negative outcomes of certain actions. ","基础语法#基础语法":"1、标题 # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 2、列表 * 项目 1 * 项目 2 * 项目 2a * 项目 2b - 项目 1 - 项目 2 - 项目 2a - 项目 2b 项目 1 项目 2 项目 2a 项目 2b 1. 项目 1 2. 项目 2 3. 项目 3 1. 项目 3a 2. 项目 3b 项目 1 项目 2 项目 3 项目 3a 项目 3b 3、文字加粗\\斜体 *这段文字将是斜体* _这也将是斜体_ **这段文字将是粗体** __这也将是粗体__ _你 **可以** 组合它们_ 这段文字将是斜体\n这也将是斜体\n这段文字将是粗体\n这也将是粗体\n你 可以 组合它们","基础语法-1#基础语法":"图片 1![GitHub Logo](https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png) 链接 1[Hugo](https://gohugo.io) Hugo\n块引用 1牛顿曾说： 2 3\u003e 如果我看得更远，那是因为我站在巨人的肩膀上。 如果我看得更远，那是因为我站在巨人的肩膀上。\n行内代码 1行内 `代码` 有 `反引号` 包围。 行内 代码 有 反引号 包围。\n代码块 语法高亮 1```go 2func main() { 3 fmt.Println(\"Hello World\") 4} 5``` 1func main() { 2 fmt.Println(\"Hello World\") 3} 表格 1| Syntax | Description | 2| --------- | ----------- | 3| Header | Title | 4| Paragraph | Text | Syntax Description Header Title Paragraph Text ","特殊案例#特殊案例：":"1、内容加 “边框” 1\u003cdiv style=\"border: 0.5px solid DarkCyan; border-radius: 10px; width: 100%; border-left-width: 5px; padding: 10px;\"\u003e 2 这是有边框的文字\u003cbr\u003e 3 这是有边框的文字\u003cbr\u003e 4 这是有边框的文字\u003cbr\u003e 5 ...... 6\u003c/div\u003e 这是有边框的文字\n这是有边框的文字\n这是有边框的文字\n...... 2、内容 “分栏” 1\u003cdiv style=\"display: flex; justify-content: center; width: 100%;\"\u003e 2 \u003cdiv style=\"flex: 33%; padding: 10px; box-sizing: border-box; text-align: center;\"\u003e 第 1 栏 \u003c/div\u003e 3 \u003cdiv style=\"flex: 33%; padding: 10px; box-sizing: border-box; text-align: center;\"\u003e 第 2 栏 \u003c/div\u003e 4 \u003cdiv style=\"flex: 33%; padding: 10px; box-sizing: border-box; text-align: center;\"\u003e 第 3 栏 \u003c/div\u003e 5\u003c/div\u003e 第 1 栏 第 2 栏 第 3 栏 "},"title":"Markdown"},"/guide/math_calculus/":{"data":{"":"","good#good":"test "},"title":"微积分"},"/guide/math_linear_algebra/":{"data":{"":"","#":"1、定义 1.1、一般形式：\n一个 $m\\times n$ 的矩阵 $\\boldsymbol{A}$ 可以表示为： $\\boldsymbol{A}=\\begin{bmatrix}a_{11}\u0026a_{12}\u0026\\cdots\u0026a_{1n} \\\\ a_{21}\u0026a_{22}\u0026\\cdots\u0026a_{2n} \\\\ \\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots \\\\ a_{m1}\u0026a_{m2}\u0026\\cdots\u0026a_{mn}\\end{bmatrix}$ ，其中 $a_{ij}$ 或 $\\boldsymbol{A}_{ij}$ 表示矩阵 $\\boldsymbol{A}$ 的第 $i$ 行第 $j$ 列的元素。 1.2、特殊矩阵：\n方阵：当矩阵的行数 $m$ 等于列数 $n$ 时，称为 $n$ 阶方阵 零矩阵：所有元素都为 0 的矩阵，记为 $\\boldsymbol{O}$ 单位矩阵：主对角线元素都为 1，其余元素都为 0 的方阵，记为 $\\boldsymbol{I}$（或 $\\boldsymbol{E}$ ）。对于 $n$ 阶单位矩阵，通常表示为 $\\boldsymbol{I}_n$ 2、基本运算 2.1、数乘：\n标量 $c$ 与矩阵 $\\boldsymbol{A}$ 的数乘，$c\\boldsymbol{A}$ 中的元素是 $\\boldsymbol{A}$ 的对应元素与 $c$ 的乘积。 $$2\\cdot\\begin{bmatrix}2\u00268\u0026-3 \\\\ 6\u0026-2\u00265\\end{bmatrix}=\\begin{bmatrix}2\\cdot2\u00262\\cdot8\u00262\\cdot(-3) \\\\ 2\\cdot6\u00262\\cdot(-2)\u00262\\cdot5\\end{bmatrix}=\\begin{bmatrix}4\u002616\u0026-6 \\\\ 12\u0026-4\u002610\\end{bmatrix}$$ 2.2、转置：\n一个 $m \\times n$ 的矩阵 $\\boldsymbol{A}$ 的转置，是一个 $n\\times m$ 的矩阵，记作 $\\boldsymbol{A}^T$，转置矩阵 $\\boldsymbol{A}^T$ 第 $i$ 行第 $j$ 列的元素是原矩阵 $\\boldsymbol{A}$ 第 $j$ 行第 $i$ 列的元素（行列互换）。 $$\\begin{bmatrix}1\u00264\u00263 \\\\ 0\u0026-5\u00267\\end{bmatrix}^T=\\begin{bmatrix}1\u00260 \\\\ 4\u0026-5 \\\\ 3\u00267\\end{bmatrix}$$ $$c(\\boldsymbol{A}^T) = c(\\boldsymbol{A})^T$$ 2.3、加（减）法：\n$m \\times n$ 矩阵 $\\boldsymbol{A}$ 和 $\\boldsymbol{B}$ 的加（减）：$\\boldsymbol{A} \\pm \\boldsymbol{B} = \\boldsymbol{C}$ 为一个 $m\\times n$ 矩阵，其中 $\\boldsymbol{C}$ 中的元素是 $\\boldsymbol{A}$ 和 $\\boldsymbol{B}$ 相应元素的加（减）：$c_{ij} = a_{ij} + b_{ij}$，$1 \\leq i \\leq m$，$1 \\leq j \\leq n$。 $$\\begin{bmatrix}1\u00263\u00261 \\\\ 1\u00260\u00260\\end{bmatrix}+\\begin{bmatrix}1\u00260\u00265 \\\\ 7\u00265\u00260\\end{bmatrix}=\\begin{bmatrix}1+1\u00263+0\u00261+5 \\\\ 1+7\u00260+5\u00260+1\\end{bmatrix}=\\begin{bmatrix}2\u00263\u00266 \\\\ 8\u00265\u00260\\end{bmatrix}$$ $$\\boldsymbol{A} + \\boldsymbol{B} = \\boldsymbol{B} + \\boldsymbol{A}$$ $$(\\boldsymbol{A} + \\boldsymbol{B})^T = \\boldsymbol{A}^T + \\boldsymbol{B}^T$$ $$c(\\boldsymbol{A} + \\boldsymbol{B}) = c\\boldsymbol{A} + c\\boldsymbol{B}$$ "},"title":"线性代数"},"/guide/math_mathematical_statistics/":{"data":{"":"","good#good":"test "},"title":"数理统计"},"/guide/math_probability_theory/":{"data":{"a1-概率论原理#A.1 概率论原理":"随机试验是其结果不能提前以确定的方式预测的试验（Ross 1987；Casella 和 Berger 1990）。所有可能的结果的集合称作样本空间 ( S )。一个样本空间是离散的，如果它由结果的有限(或可数无限)集组成；否则是连续的。( S ) 的任意子集 ( E ) 是一个事件。事件是集合，并且我们可以谈论它们的补、交、并等。\n概率的一种解释是频率 (frequency)。当一个试验在完全相同的条件下不断重复时，对于任意事件 ( E )，结果在 ( E ) 中的次数所占的比例趋向于某个常数值。这个常数极限频率是事件的概率，而我们也记作 ( P(E) )。\n有时，概率可解释成可存程度 (degree of belief)。例如，当我们说土耳其赢得 2010 年足球世界杯冠军的概率时，我们并不是指出现的频率，因为 2010 年足球世界杯只进行一次，并且(在写本书时)它还未进行。在这种情况下，我们的意思是我们在观察相位事件中出现的程度。由于是主观的，因此对同一事件，不同的人可能指派不同的概率。\nA.1.1 概率论公理 公理确保随机试验中指派的概率可以解释成相对频率，并且这些指派符合我们对相对频率之间关系的直观理解：\n( 0 \\leq P(E) \\leq 1 )。如果 ( E_1 ) 是不可能出现的事件，则 ( P(E_1) = 0 )。如果 ( E_2 ) 是一定出现的事件，则 ( P(E_2) = 1 )。\n如果 ( S ) 是包含所有可能结果的样本空间，则 ( P(S) = 1 )。\n如果 ( E_i, i = 1, \\cdots, n )，是互斥的(即如果它们不可能同时出现：( E_i \\cap E_j = \\emptyset, i \\neq j )，其中 (\\emptyset) 是不包含任何可能结果的空事件)，则我们有\n[ P\\left(\\bigcup_{i=1}^{n} E_i\\right) = \\sum_{i=1}^{n} P(E_i) ]\n（A.1）\n例如，设 ( E^c ) 表示 ( E ) 的补，由不在 ( E ) 中的 ( S ) 中所有可能的结果组成，我们有 ( E \\cap E^c = \\emptyset )，并且\n[ P(E \\cup E^c) = P(E) + P(E^c) = 1 ]\n[ P(E^c) = 1 - P(E) ]\n如果 ( E ) 和 ( F ) 的交非空，则我们有\n[ P(E \\cup F) = P(E) + P(F) - P(E \\cap F) ]\n（A.2）","概率论#概率论":"概率论我们简略回顾概率论原理、随机变量概念和实例分布。"},"title":"概率论"},"/guide/program_go/":{"data":{"":"","good#good":"test "},"title":"Go"},"/guide/program_java/":{"data":{"":"","good#good":"test "},"title":"Java"},"/guide/program_linux/":{"data":{"":"","-其他命令#🛠️ 其他命令":" 命令 作用 ","-其他实用工具#🛠️ 其他实用工具":" 命令 作用 示例 tar 压缩/解压文件 tar -czvf archive.tar.gz dir/\ntar -xzvf archive.tar.gz crontab 定时任务管理 crontab -e（编辑）\ncrontab -l（查看） history 查看命令历史 history | grep \"apt\" alias 设置命令别名 alias ll='ls -alF' ","-用户与权限管理#👥 用户与权限管理":" 命令 作用 示例 useradd 添加用户 useradd -m newuser passwd 修改密码 passwd username sudo 提权执行命令 sudo apt update chmod 修改权限 chmod 755 script.sh chown 修改文件所有者 chown user:group file.txt ","-系统信息与管理#🖥️ 系统信息与管理":" 命令 作用 示例 top/htop 实时进程监控 top\nhtop（需安装） ps 查看进程 ps aux ps -ef|grep nginx kill 终止进程 kill -9 1234（强制终止 PID 1234） df 查看磁盘空间 df -h（人类可读格式） du 查看目录大小 du -sh /home/（汇总大小） free 查看内存使用 free -h systemctl 管理系统服务 systemctl start nginx\nsystemctl status sshd shutdown 关机/重启 shutdown now\nreboot ","-网络操作#🌐 网络操作":" 命令 作用 示例 ping 测试网络连通性 ping google.com ifconfig/ip 查看/配置网络接口 ifconfig\nip addr curl/wget 下载文件 curl -O http://example.com/file\nwget http://example.com/file ssh 远程登录 ssh user@192.168.1.1 scp 远程复制文件 scp file.txt user@host:/path/ netstat/ss 查看网络连接/端口 netstat -tulnp\nss -tulnp ","-软件包管理#📦 软件包管理":" 命令（Debian/Ubuntu） 命令（RHEL/CentOS） 作用 示例 apt update yum update 更新软件包列表 sudo apt update apt install yum install 安装软件 sudo apt install nginx apt remove yum remove 卸载软件 sudo apt remove nginx dpkg -i rpm -i 安装本地包 sudo dpkg -i package.deb ","1-linux-概述#1. Linux 概述":"1.1. Linux 是什么？ Linux 是一个开源、免费的操作系统内核，由芬兰程序员 Linus Torvalds 在 1991 年 首次发布。 广泛应用于服务器、超级计算机、嵌入式设备（如路由器、智能电视）以及个人电脑（如 Ubuntu、Fedora）。 1.2. Linux 系统目录结构 1/\t[根目录，所有目录的起点] 2├── bin [核心命令：存放系统启动和运行必需的基础命令，如 ls/cp/bash] 3├── sbin [管理员命令：存放系统管理命令，如 iptables/reboot，需 root 权限] 4├── boot [启动文件：包含内核(vmlinuz)和引导加载器(GRUB)文件] 5├── dev [设备文件：硬件设备抽象文件，如 /dev/sda(硬盘)、/dev/tty(终端)] 6├── etc [配置文件：系统和应用程序的配置，如 /etc/passwd(用户)、/etc/nginx/] 7├── home [用户目录：普通用户的家目录，如 /home/username 存放个人文件] 8├── root [root家目录：超级用户的家目录，普通用户无权访问] 9├── lib [核心库：存放/bin和/sbin所需的共享库(.so文件)] 10├── usr [用户软件：相当于Windows的Program Files] 11│ ├── bin [非必需的用户命令] 12│ ├── sbin [非必需的管理命令] 13│ └── lib [应用程序库文件] 14├── opt [第三方软件：商业软件或大型应用，如 Oracle/Matlab] 15├── proc [内核/进程信息：虚拟文件系统，实时反映进程和内核状态] 16├── sys [系统设备：虚拟文件系统，管理设备驱动和内核参数] 17数据：存放系统启动后的临时文件(如PID文件)] 18├── var [可变数据：经常变化的文件] 19│ ├── log [系统日志：如 /var/log/syslog] 20│ └── cache [应用程序缓存] 21├── tmp [临时文件：所有用户可读写，重启后通常清空] 22├── mnt [手动挂载：临时挂载点(如U盘/硬盘)] 23└── media [自动挂载：可移动设备自动挂载点(如光盘/U盘)] 1.3. Linux 文件基本属性: Tip\nLinux 系统是一种典型的多用户系统，不同的用户处于不同的地位，拥有不同的权限。\n1文件类型 所有者权限 组权限 其他用户权限 2 ↓ ↓ ↓ ↓ 3 - r w x r - - r - - 4 ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ 5 │ │ └执行 │ │ └执行 │ │ └执行 6 │ └─写入 │ └─写入 │ └─写入 7 └──读取 └──读取 └──读取 1️⃣ 文件类型：\nd（文件\\目录）； -（文本、二进制、压缩包等常规文件）； l（符号链接，指向另一个文件的快捷方式（软链接）） …… 2️⃣ 用户身份划分：\n所有者（Owner）：文件的创建者/拥有者，拥有最高控制权。 所属组（Group）：文件所属的用户组，组内成员共享组权限。 其他用户（Others）：既不是所有者也不在所属组的其他用户。 3️⃣ 权限类型：每种用户身份对应三种基本权限：\n读 r：查看文件内容或列出目录内容。 写 w：修改文件内容或在目录中创建/删除文件。 执行 x：运行文件（如脚本）或进入目录。 4️⃣ 权限表示法：符号模式；数字模式\n符号模式： 用 r，w，x 表示权限； 数字模式： 用八进制数表示，每位数字对应 r=4、w=2、x=1 的和； 符号模式 数字模式 权限案例 rw-r--r-- 644 所有者 rw-（读写） 6 = 4+2（读写） 所属组 r--（只读） 4 = 4（只读） 其他用户 r--（只读） 4 = 4（只读） 1.4. Linux 常用命令 📂 文件\\文件夹权限 ls, chmod, chown, chgrp 📂 文件\\文件夹权限： 1️⃣ 使用 ls -l 命令查看文件权限：\n1$ ls -l 2-rw-r--r-- 1 alice dev 1024 Sep 1 10:00 file.txt 第1字段 -rw-r--r--：文件类型和权限。 第3字段 alice：所有者。 第4字段 dev：所属组。 2️⃣ chmod 更改权限\n1$ chmod u+x script.sh 2$ chmod g-w file.txt 3$ chmod 755 script.sh 给所有者添加执行权限 移除所属组的写权限 数字模式：rwxr-xr-x 3️⃣ chown 更改所有者和所属组\n1$ chown alice:dev file.txt 修改所有者为 alice，组为 dev 4️⃣ chgrp 单独修改所属组\n1$ chgrp dev file.txt 🛣 路径查看\\切换： ：\n👻\n：\n文件与目录操作 命令 作用\\实例 xx --help 查看帮助： pwd 1️⃣ $ cd /home（切换目录）\n$ cd ..（返回上级） ls 1️⃣ $ ls -l（列出目录内容）\n2️⃣ $ ls -a（显示隐藏文件） chmod 1️⃣ $ chmod u+x test.sh（）\n2️⃣ $ chmod g-w file.txt（）\n$ chmod 755 test.sh（） touch 创建空文件或更新时间戳\n$ touch newfile.txt https://www.unicode.org/emoji/charts/full-emoji-list.html\n命令 作用 示例 mkdir 创建目录 mkdir dir\nmkdir -p dir1/dir2（递归创建） rm 删除文件/目录 rm file.txt\nrm -r dir/（递归删除）\nrm -f file 或 dir/（强制删除） cp 复制文件/目录 cp file1.txt file2.txt\ncp -r dir1/ dir2/ mv 移动/重命名文件 mv old.txt new.txt\nmv file /tmp/ cat 查看文件内容 cat file.txt grep 文本搜索 grep \"error\" log.txt\ngrep -r \"pattern\" /dir/ find 查找文件 find /home -name \"*.txt\" ","good#good":"test ","参考网址#参考网址：":" https://www.w3ccoo.com/linux/ https://www.tutorialspoint.com/unix/unix-getting-started.htm "},"title":"Linux\\Shell"},"/guide/program_python/":{"data":{"":"","good#good":"test "},"title":"Python"},"/guide/program_scala/":{"data":{"":"","good#good":"test "},"title":"Scala"},"/guide/python_flask/":{"data":{"":"","good#good":"test "},"title":"Python_Flask"},"/guide/python_folium/":{"data":{"":"","good#good":"test "},"title":"Python_Folium"},"/guide/python_geopandas/":{"data":{"":"","good#good":"test "},"title":"Python_GeoPandas"},"/guide/python_matplotlib/":{"data":{"":"","0-速查表#0. 速查表":" 对象 设置 方法 OO-style pyplot-style 创建 Figure _ fig = plt.figure(figsize=(3,3)) plt.figure(figsize=(3,3)) 创建 Axes _ fig, ax = plt.subplots(figsize=(3,3)) plt.plot() 标题 内容 _ ax.set_title('Title') plt.title('Title') 标题 格式 参数 ax.set_title('Title', loc='left', font='Georgia', size=12, color='gray', weight='bold') plt.title('Title', loc='left', font='Georgia', size=12, color='gray', weight='bold') 标题 格式 参数字典 format_dir = {'fontproperties': 'Georgia', 'fontsize': 15, 'color': 'Gray', 'fontweight': 'bold'}\nax.set_title('Title', loc='left', **format_dir) format_dir = {'fontproperties': 'Georgia', 'fontsize': 15, 'color': 'Gray', 'fontweight': 'bold'}\nplt.title('Title', loc='left', **format_dir) 标题 位置 简单设置 ax.set_title('Title', loc='left') \u003cloc\u003e: ’left’,‘center’,‘right’ plt.title(\"Title\", loc='left') \u003cloc\u003e: ’left’,‘center’,‘right’ 设置类容 OO-style pyplot-style 关闭 坐标轴 ax.axis('off')# 关闭所有坐标轴 ax.spines['top'].set_visible(False) plt.axis('off') # 关闭所有坐标轴 plt.gca().spines['top'].set_visible(False) 坐标轴 颜色 ax..spines['bottom'].set_color('red') plt.gca().spines['bottom'].set_color('red') 坐标轴 粗细 ax.spines['left'].set_linewidth(0.5) plt.gca().spines['left'].set_linewidth(0.5) 坐标轴 位置 1\n单个参数 ax.spines[\"right\"].set_position()\n# `` 坐标轴 位置 1 ax.spines[\"right\"].set_position((\"outward\", 5))\n# “inward”：向内，“outward”：向外 plt.gca().spines[\"right\"].set_position((\"outward\", 5)) # “inward”：向内，“outward”：向外 `` `` ","1-概述#1. 概述":"1.1. 编码风格 (1). the OO-style 1import numpy as np 2import matplotlib.pyplot as plt 3 4x = np.linspace(0, 2, 100) # Sample data. 5 6 7fig, ax = plt.subplots(figsize=(3.5, 3), layout='constrained') # Create a figure 8 9ax.plot(x, x, label='linear') # Plot some data on the Axes. 10ax.plot(x, x**2, label='quadratic') # Plot more data on the Axes... 11 12ax.set_title(\"Simple Plot\") # Add a title to the Axes. 13 14ax.set_xlabel('x label') # Add an x-label to the Axes. 15ax.set_ylabel('y label') # Add a y-label to the Axes. 16 17ax.legend() # Add a legend. 18 19plt.show() # Show the figure. (2). pyplot-style 1import numpy as np 2import matplotlib.pyplot as plt 3 4x = np.linspace(0, 2, 100) # Sample data. 5 6 7plt.figure(figsize=(3.5, 3), layout='constrained') 8 9plt.plot(x, x, label='linear') # Plot some data on the (implicit) Axes. 10plt.plot(x, x**2, label='quadratic') # etc. 11 12plt.title(\"Simple Plot\") 13 14plt.xlabel('x label') 15plt.ylabel('y label') 16 17plt.legend() # Add a legend. 18 19plt.show() # Show the figure. 1.2. 图形结构 (1). Figure 📝 Figure 是整个窗体，你可以把它想象成一个画板，我们在其上面创建图形进，这是最为外层的对象。 Figure 可以将其看作是整个绘图区域的容器 一个 Figure 对象可以包含一或多个 Axes （子图）对象。 OO-stylepyplot-style 1import matplotlib.pyplot as plt 2 3# an empty figure with no Axes 4fig = plt.figure(figsize=(3.5, 3), layout='constrained') 5 6plt.show() 输出结果如下：\n\u003cFigure size 350x300 with 0 Axes\u003e 1import matplotlib.pyplot as plt 2 3# an empty figure with no Axes 4plt.figure(figsize=(3.5, 3), layout='constrained') 5 6plt.show() 输出结果如下：\n\u003cFigure size 350x300 with 0 Axes\u003e (2). Axes 📝 Axes （子图）对象，是实际进行绘图操作的区域，包含坐标轴、数据点、线条、图例等元素。 Axes 可以将其看作是包含绘图元素（例如线、点、刻度、标签、图例等）的一个容器。 Axes 指子图，每个子图可以用任一种坐标系表示。如笛卡尔坐标系（直角坐标系），它包含两个 Axis 对象。每个 Axes 都有一个标题，一个 x 标签和一个 y 标签。在这个坐标系内，我们可以绘制各种图形。 OO-stylepyplot-style 1import matplotlib.pyplot as plt 2 3# Create a figure with a single Axes 4fig, ax = plt.subplots(figsize=(3.5, 3)) 5 6plt.show() 输出结果如下：\n1import matplotlib.pyplot as plt 2 3# Create a figure 4plt.figure(figsize=(3.5, 3)) 5 6# Create a single Axes 7plt.plot() 8 9plt.show() 输出结果如下：\n(3). Axis 📝 Axis （轴）对象，用于控制图形中的刻度、刻度标签和网格线。 每个 Axes 对象有一个 XAxis 对象和一个 YAxis 对象。 Axis 的主要功能包括：设置标签格式；刻度位置；刻度标签、字体、颜色；刻度线粗细、颜色；网格线显示与否、样式等； OO-stylepyplot-style 1import matplotlib.pyplot as plt 2 3# Create a figure containing a single Axes. 4fig, ax = plt.subplots(figsize=(3.5, 3)) 5 6# Plot some data on the Axes. 7ax.plot([1, 2, 3, 4], [1, 4, 2, 3]) 8 9# Create label formatting dictionary 10label_format = {'fontproperties': 'Georgia', 'fontsize': 10, 'color': 'Gray', 'fontweight': 'bold'} 11 12# Set title 13ax.set_title('This is Title', **label_format, size=15) 14 15# Set labels for the x-axis and y-axis 16ax.set_xlabel('X Axis Title Here', **label_format) 17ax.set_ylabel('Y Axis Title Here', **label_format) 18 19# Show the figure 20plt.show() 输出结果如下：\n1import matplotlib.pyplot as plt 2 3plt.figure(figsize=(3.5, 3)) 4 5plt.plot([1, 2, 3, 4], [1, 4, 2, 3]) 6 7# Create label formatting dictionary 8label_format = {'fontproperties': 'Georgia', 'fontsize': 10, 'color': 'Gray', 'fontweight': 'bold'} 9 10plt.title('This is Title', **label_format, size=15) 11 12plt.xlabel('X Axis Title Here', **label_format) 13plt.ylabel('Y Axis Title Here', **label_format) 14 15plt.show() 输出结果如下：","2-颜色#2. 颜色":"","3-文本#3. 文本":"","4-figure-图形设置#4. Figure 图形设置":"","5-axes-子图细节设置#5. Axes 子图细节设置":"5.1. 标题： 1️⃣ OO-style 位置 2️⃣ OO-style 格式参数 3️⃣ OO-style 格式字典 4️⃣ pyplot-style 位置 5️⃣ pyplot-style 格式参数 6️⃣ pyplot-style 格式字典 1import matplotlib.pyplot as plt 2 3fig, ax = plt.subplots(figsize=(3,3)) 4 5ax.plot([1, 2, 3, 4], [8, 4, 2, 3]) 6 7ax.set_title('Title', loc='left') 8 9plt.show() 1import matplotlib.pyplot as plt 2 3fig, ax = plt.subplots(figsize=(3,3)) 4 5ax.plot([1, 2, 3, 4], [8, 4, 2, 3]) 6 7# Set title 8ax.set_title('This is Title', loc='left', font='Georgia', size=12, color='gray', weight='bold') 9 10plt.show() 1import matplotlib.pyplot as plt 2 3fig, ax = plt.subplots(figsize=(3,3)) 4 5ax.plot([1, 2, 3, 4], [8, 4, 2, 3]) 6 7# Create label formatting dictionary 8format_dir = {'fontproperties': 'Georgia', 'fontsize': 15, 'color': 'Gray', 'fontweight': 'bold'} 9 10# Set title 11ax.set_title('This is Title', loc='left', **format_dir) 12 13plt.show() 1import matplotlib.pyplot as plt 2 3# Create a figure 4plt.figure(figsize=(3, 3)) 5 6# Create a single Axes 7plt.plot([1, 2, 3, 4], [8, 4, 2, 3]) 8 9plt.title(\"Title\", loc='left') # 将标题设置在左侧 10 11plt.show() 1import matplotlib.pyplot as plt 2 3plt.figure(figsize=(3,3)) 4 5plt.plot([1, 2, 3, 4], [8, 4, 2, 3]) 6 7# Set title 8plt.title('Title', loc='left', font='Georgia', size=12, color='gray', weight='bold') 9 10plt.show() 1import matplotlib.pyplot as plt 2 3plt.figure(figsize=(3, 3)) 4 5plt.plot([1, 2, 3, 4], [8, 4, 2, 3]) 6 7# Create label formatting dictionary 8format_dir = {'fontproperties': 'Georgia', 'fontsize': 15, 'color': 'Gray', 'fontweight': 'bold'} 9 10# Set title 11plt.title('Title', loc='left', **format_dir) 12 13plt.show() 5.2. 坐标轴： OO-stylepyplot-style 1 输出结果如下：\n1 输出结果如下：","6-多子图绘制#6. 多子图绘制":"6.1. "},"title":"Python_Matplotlib"},"/guide/python_numpy/":{"data":{"":"","good#good":"test "},"title":"Python_Numpy"},"/guide/python_pandas/":{"data":{"":"","good#good":"test "},"title":"Python_Pandas"},"/guide/python_plotly/":{"data":{"":"","good#good":"test "},"title":"Python_Plotly"},"/guide/python_seaborn/":{"data":{"":"","good#good":"test "},"title":"Python_Seaborn"},"/guide/python_shap/":{"data":{"":"","good#good":"test "},"title":"Python_SHAP"},"/guide/python_sklearn/":{"data":{"":"","good#good":"test "},"title":"Python_Sklearn"},"/guide/python_sklearn_source_code/":{"data":{"":"","good#good":"test "},"title":"Python_Sklearn 源码"},"/guide/python_statsmodels/":{"data":{"":"","good#good":"test "},"title":"Python_Statsmodels"},"/guide/python_streamlit/":{"data":{"":"","good#good":"test "},"title":"Python_Streamlit"},"/project/":{"data":{"":" 数据竞赛kaggle，阿里天池… 测试 数仓项目B 站，数仓项目学习（尚硅谷，等）； 测试 可视化Python，Datart，观远BI，PowerBI… 测试 "},"title":"项目"},"/project/bigdata/":{"data":{"":"\n1️⃣ 数据仓库 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 B 站 Header ⭐ Github Jupyterlab Demo 2 尚硅谷 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 3 尚硅谷 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 4 尚硅谷 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 5 尚硅谷 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 6 尚硅谷 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo "},"title":"大数据项目"},"/project/competition/":{"data":{"":" 1️⃣入门 2️⃣分类 3️⃣回归 4️⃣聚类 5️⃣NLP 6️⃣CV 7️⃣数据分析 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 Kaggle Header Header Header Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 Kaggle Header Header Header Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 Kaggle Header Header Header Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 Kaggle Header Header Header Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 Kaggle Header Header Header Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 Kaggle Header Header Header Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 Kaggle Header Header Header Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo "},"title":"数据竞赛"},"/project/competition/page_001_test/":{"data":{"":"","test#test":"这篇文章提供了一些基础的 Markdown 语法样例，这些可以在 Hugo 的内容文件中使用。\n1import pandas as pd 2pd.__version__ '2.2.2' test 这是有边框的文字\n这是有边框的文字\n这是有边框的文字\n...... 第 1 栏 第 2 栏 第 3 栏 1import pandas as pd 2 3data = { 4 'test': [ 5 '2024-01-01 16:50:15' 6 ,'2024-12-09 23:11:49' 7 ,'2024-12-08 09:30:57' 8 ,'2024-12-31 09:30:57' 9 ] 10} 11 12date_df = pd.DataFrame(data) 13 14date_df.info() \u003cclass 'pandas.core.frame.DataFrame'\u003e RangeIndex: 4 entries, 0 to 3 Data columns (total 1 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 test 4 non-null object dtypes: object(1) memory usage: 164.0+ bytes test 1date_df['test'] = pd.to_datetime( 2 date_df['test'] 3 ) 4 5print(date_df.info()) 6date_df \u003cclass 'pandas.core.frame.DataFrame'\u003e RangeIndex: 4 entries, 0 to 3 Data columns (total 1 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 test 4 non-null datetime64[ns] dtypes: datetime64[ns](1) memory usage: 164.0 bytes None test 0 2024-01-01 16:50:15 1 2024-12-09 23:11:49 2 2024-12-08 09:30:57 3 2024-12-31 09:30:57 test 0 2024-01-01 16:50:15 1 2024-12-09 23:11:49 2 2024-12-08 09:30:57 3 2024-12-31 09:30:57 1import matplotlib.pyplot as plt 2import numpy as np 3 4data = {'Barton LLC': 109438.50, 5 'Frami, Hills and Schmidt': 103569.59, 6 'Fritsch, Russel and Anderson': 112214.71, 7 'Jerde-Hilpert': 112591.43, 8 'Keeling LLC': 100934.30, 9 'Koepp Ltd': 103660.54, 10 'Kulas Inc': 137351.96, 11 'Trantow-Barrows': 123381.38, 12 'White-Trantow': 135841.99, 13 'Will LLC': 104437.60} 14group_data = list(data.values()) 15group_names = list(data.keys()) 16group_mean = np.mean(group_data) 1def currency(x, pos): 2 \"\"\"The two arguments are the value and tick position\"\"\" 3 if x \u003e= 1e6: 4 s = f'${x*1e-6:1.1f}M' 5 else: 6 s = f'${x*1e-3:1.0f}K' 7 return s 1fig, ax = plt.subplots(figsize=(8, 8)) 2ax.barh(group_names, group_data) 3labels = ax.get_xticklabels() 4plt.setp(labels, rotation=45, horizontalalignment='right') 5 6# Add a vertical line, here we set the style in the function call 7ax.axvline(group_mean, ls='--', color='r') 8 9# Annotate new companies 10for group in [3, 5, 8]: 11 ax.text(145000, group, \"New Company\", fontsize=10, 12 verticalalignment=\"center\") 13 14# Now we move our title up since it's getting a little cramped 15ax.title.set(y=1.05) 16 17ax.set(xlim=[-10000, 140000], xlabel='Total Revenue', ylabel='Company', 18 title='Company Revenue') 19ax.xaxis.set_major_formatter(currency) 20ax.set_xticks([0, 25e3, 50e3, 75e3, 100e3, 125e3]) 21#fig.subplots_adjust(right=.1) 22 23plt.show() "},"title":"2025测试"},"/project/visualization/":{"data":{"":" 1️⃣BI看板 2️⃣图表 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 Kaggle Header Header Header Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 序号 项目来源 项目名称 项目难度 代码 笔记 部署 1 Kaggle Header Header Header Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo 2 天池 Header ⭐⭐⭐⭐⭐ Github Jupyterlab Demo "},"title":"数据可视化"}}